name: Test Agentic Workflows

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '*.py'
      - '.github/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '*.py'
      - '.github/**'
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode to run'
        required: false
        default: 'ci'
        type: choice
        options:
        - ci
        - local

jobs:
  # Unit tests - always run first (fastest feedback)
  unit-tests:
    runs-on: ubuntu-latest
    name: "Unit Tests (Fast)"
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-xdist

    - name: Run unit tests
      run: |
        cd backend
        python -m pytest tests/unit_tests/ \
          --disable-warnings \
          -v \
          --tb=short
    
    - name: Upload unit test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-test-results
        path: backend/tests/unit_tests/test-results/

  # Integration tests - run after unit tests pass
  integration-tests:
    runs-on: ubuntu-latest
    name: "Integration Tests (Core Pipeline)"
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-xdist

    - name: Run core integration tests
      env:
        PYTEST_TEST_MODE: ci
      run: |
        cd backend
        echo "ðŸ§ª Running core integration tests..."
        
        # Focus on system integration and pipeline logic
        python -m pytest pipeline_system_tests/test_full_system_integration.py \
          -v \
          --tb=short \
          --disable-warnings \
          --timeout=120
        
        # Run other integration tests (may include API calls)
        python -m pytest tests/integration_tests/ \
          -k "not api" \
          -v \
          --tb=short \
          --disable-warnings \
          --timeout=60
      timeout-minutes: 10
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: backend/tests/integration_tests/test-results/

  # Audio testing documentation - manual testing guidance
  audio-testing-guide:
    runs-on: ubuntu-latest
    name: "Audio Testing Guide"
    if: github.event_name == 'workflow_dispatch'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Create audio testing documentation
      run: |
        cat > AUDIO_TESTING.md << 'EOF'
        # ðŸŽ¤ Audio Testing Guide
        
        ## Why Audio Tests Are Not in CI/CD
        
        Audio processing tests are excluded from CI/CD because they:
        - Require heavyweight AI models (Whisper) 
        - Need actual audio files
        - Have threading/stability issues in containerized environments
        - Take significant time and resources
        
        ## Local Audio Testing
        
        ### Prerequisites
        ```bash
        # Install audio dependencies
        pip install -r requirements.txt
        
        # Ensure you have test audio files
        # Place .m4a files in backend/pipeline_system_tests/
        ```
        
        ### Manual Testing Commands
        ```bash
        cd backend
        
        # Test voice-to-text engine
        python -c "
        from voice_to_text.voice_to_text import VoiceToTextEngine
        engine = VoiceToTextEngine()
        result = engine.process_audio_file('path/to/your/audio.m4a')
        print(f'Transcript: {result}')
        "
        
        # Test full pipeline with real audio
        python ../process_transcription.py --audio path/to/your/audio.m4a
        ```
        
        ### Integration Testing
        ```bash
        # Test the complete pipeline
        python -m pytest pipeline_system_tests/test_full_system_integration.py::TestFullSystemIntegration::test_full_system_with_real_audio -v -s
        ```
        
        ## What CI/CD Tests Instead
        
        - âœ… Core tree processing logic
        - âœ… System integration points  
        - âœ… API workflows (with real LLM calls)
        - âœ… Error handling and recovery
        - âœ… Mocked pipeline components
        
        ## Quality Assurance
        
        Before releasing, manually verify:
        1. Audio transcription works with sample files
        2. Complete pipeline: Audio â†’ Tree â†’ Markdown
        3. Real-time processing doesn't crash
        4. Memory usage is reasonable
        EOF
        
        echo "ðŸ“ Audio testing documentation created"
        
    - name: Upload audio testing guide
      uses: actions/upload-artifact@v4
      with:
        name: audio-testing-guide
        path: AUDIO_TESTING.md

  # API integration tests - only on main/develop or manual trigger with API key
  api-integration-tests:
    runs-on: ubuntu-latest
    name: "API Integration Tests (CI Mode)"
    needs: integration-tests
    if: |
      github.ref == 'refs/heads/main' || 
      github.ref == 'refs/heads/develop' || 
      github.event_name == 'workflow_dispatch'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-xdist

    - name: Check environment setup and API key
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        echo "ðŸ” Environment Check:"
        echo "Python version: $(python --version)"
        echo "Pip version: $(pip --version)"
        echo "Working directory: $(pwd)"
        
        echo ""
        echo "ðŸ”‘ API Key Check:"
        if [[ -n "$GOOGLE_API_KEY" ]]; then
          echo "âœ… GOOGLE_API_KEY is set"
          echo "   Length: ${#GOOGLE_API_KEY} characters"
          echo "   First 10 chars: ${GOOGLE_API_KEY:0:10}..."
          echo "   Last 5 chars: ...${GOOGLE_API_KEY: -5}"
        else
          echo "âŒ GOOGLE_API_KEY is not set"
          echo "   Repository secret may be missing or not accessible"
        fi
        
        echo ""
        echo "ðŸ“¦ Package Check:"
        python -c "
        try:
            import google.generativeai as genai
            print('âœ… google-generativeai package available')
            print(f'   Version: {genai.__version__}')
        except ImportError as e:
            print(f'âŒ google-generativeai package not available: {e}')
        "
        
        echo ""
        echo "ðŸ“ File structure:"
        ls -la backend/tests/ || echo "âŒ backend/tests/ not found"
    
    - name: Test API connectivity before running tests
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        if [[ -z "$GOOGLE_API_KEY" ]]; then
          echo "âš ï¸ GOOGLE_API_KEY not set - will skip API tests"
          exit 0
        fi
        
        echo "ðŸ§ª Testing Gemini API connectivity..."
        cd backend
        python -c "
        import os
        import sys
        
        # Test the LLM integration module
        try:
            from agentic_workflows.infrastructure.llm_integration import GEMINI_AVAILABLE, call_llm
            print(f'Gemini available: {GEMINI_AVAILABLE}')
            
            if GEMINI_AVAILABLE:
                print('âœ… API initialization successful')
                # Make a minimal test call
                try:
                    result = call_llm('Say hello', 'gemini-2.0-flash')
                    print(f'âœ… Test API call successful: {len(result)} chars')
                except Exception as e:
                    print(f'âŒ Test API call failed: {e}')
                    sys.exit(1)
            else:
                print('âŒ API initialization failed - check logs above')
                sys.exit(1)
                
        except Exception as e:
            print(f'âŒ Failed to import LLM integration: {e}')
            sys.exit(1)
        "

    - name: Run API integration tests in CI mode
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        PYTEST_TEST_MODE: ci
      run: |
        echo "ðŸš¨ CRASH-FAST MODE: API tests must pass or build fails"
        echo "The VoiceTree system requires Gemini API to function"
        
        cd backend/tests/integration_tests/agentic_workflows
        python -m pytest test_chunk_boundaries_adaptive.py test_real_examples.py \
          --test-mode=ci \
          -v \
          --tb=short
      timeout-minutes: 15  # Prevent hanging
    
    - name: Upload API test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: api-test-results
        path: backend/tests/integration_tests/agentic_workflows/test-results/
    
    - name: Comment test results on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: 'ðŸ§ª Agentic workflow tests completed! Check the "Actions" tab for detailed results.'
          })

  # Quality benchmarking - only on main/develop branches after API tests pass
  quality-benchmark:
    runs-on: ubuntu-latest
    name: "Quality Benchmark (Score >3.0)"
    needs: api-integration-tests
    if: |
      github.ref == 'refs/heads/main' || 
      github.ref == 'refs/heads/develop'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio
    
    - name: Run quality benchmarking
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        PYTHONPATH: ${{ github.workspace }}
      run: |
        # Run from project root so imports work correctly
        python backend/benchmarker/quality_tests/quality_LLM_benchmarker.py
      timeout-minutes: 10
    
    - name: Upload quality benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: quality-benchmark-results
        path: |
          backend/benchmarker/quality_log.txt
          backend/benchmarker/latest_quality_log.txt
          backend/benchmarker/quality_tests/latest_run_context.json
          oldVaults/VoiceTreePOC/QualityTest/

  # Performance benchmark - only on manual trigger
  performance-benchmark:
    runs-on: ubuntu-latest
    name: "Performance Benchmark"
    if: github.event_name == 'workflow_dispatch'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio
        
    - name: Run performance benchmarks
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        PYTEST_TEST_MODE: ci
      run: |
        cd backend/tests/integration_tests/agentic_workflows
        python -m pytest test_performance_benchmark.py \
          --test-mode=ci \
          -v \
          --tb=short 