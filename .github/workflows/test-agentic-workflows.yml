name: Test Agentic Workflows

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '*.py'
      - '.github/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '*.py'
      - '.github/**'
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode to run'
        required: false
        default: 'ci'
        type: choice
        options:
        - ci
        - local
      include_benchmarks:
        description: 'Run performance benchmarks'
        required: false
        default: false
        type: boolean
      emergency_bypass:
        description: 'Emergency bypass mode (skip API tests)'
        required: false
        default: false
        type: boolean

jobs:
  # Job 1: Fast Tests (Unit + Integration without API)
  fast-tests:
    runs-on: ubuntu-latest
    name: "Fast Tests (Unit + Integration)"
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-xdist

    - name: Run pre-flight validation (Fast Tests)
      run: |
        echo "ðŸ” Running pre-flight validation for fast tests..."
        python scripts/ci_preflight.py || echo "âš ï¸ Pre-flight validation failed - proceeding with limited tests"
      continue-on-error: true

    - name: Run unit tests
      run: |
        cd backend
        echo "ðŸ§ª Running unit tests (no API calls)..."
        python -m pytest tests/unit_tests/ \
          --disable-warnings \
          -v \
          --tb=short \
          --maxfail=5 \
          --timeout=60 \
          -n auto
    
    - name: Run integration tests (without API)
      run: |
        cd backend
        echo "ðŸ”— Running integration tests (mocked/offline)..."
        python -m pytest tests/integration_tests/ \
          -k "not api and not requires_api" \
          -v \
          --tb=short \
          --disable-warnings \
          --timeout=60 \
          --maxfail=3 \
          -n auto
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: fast-test-results
        path: |
          backend/tests/unit_tests/test-results/
          backend/tests/integration_tests/test-results/

  # Job 2: API Integration Tests (or Emergency Bypass)
  api-tests:
    runs-on: ubuntu-latest
    name: "API Integration Tests"
    needs: fast-tests
    if: |
      (github.ref == 'refs/heads/main' || 
       github.ref == 'refs/heads/develop' || 
       github.event_name == 'workflow_dispatch') &&
      github.event.inputs.emergency_bypass != 'true'
    steps:
    - name: Dummy step
      run: echo "Hello"
      
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-xdist

    - name: Pre-flight validation (API Tests)
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        echo "ðŸ” Running comprehensive pre-flight validation..."
        python scripts/ci_preflight.py
        echo "âœ… Pre-flight validation passed - proceeding with API tests"

    - name: Check API connectivity with circuit breaker reset
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        if [[ -z "$GOOGLE_API_KEY" ]]; then
          echo "âš ï¸ GOOGLE_API_KEY not set - skipping API tests"
          echo "skip_api_tests=true" >> $GITHUB_ENV
          exit 0
        fi
        
        echo "ðŸ§ª Testing Gemini API connectivity with circuit breaker protection..."
        cd backend
        python -c "
        import os
        import sys
        try:
            # Reset circuit breaker to ensure clean state
            from agentic_workflows.infrastructure.llm_integration import reset_circuit_breaker, GEMINI_AVAILABLE, call_llm
            reset_circuit_breaker()
            print(f'ðŸ”„ Circuit breaker reset, Gemini available: {GEMINI_AVAILABLE}')
            
            if GEMINI_AVAILABLE:
                result = call_llm('Say hello', 'gemini-2.0-flash')
                print(f'âœ… API test successful: {len(result)} chars')
            else:
                print('âŒ API initialization failed - check pre-flight validation logs above')
                sys.exit(1)
        except Exception as e:
            if 'CIRCUIT_BREAKER_TRIPPED' in str(e):
                print('ðŸ”´ Circuit breaker activated - API unavailable, stopping to prevent log spam')
            else:
                print(f'âŒ API test failed: {e}')
            sys.exit(1)
        "

    - name: Run API integration tests
      if: env.skip_api_tests != 'true'
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        PYTEST_TEST_MODE: ${{ github.event.inputs.test_mode || 'ci' }}
      run: |
        cd backend
        echo "ðŸš¨ Running API integration tests..."
        
        # Core pipeline integration with real APIs
        python -m pytest pipeline_system_tests/test_full_system_integration.py \
          -v \
          --tb=short \
          --disable-warnings \
          --timeout=120 \
          --maxfail=3
        
        # Agentic workflow API tests
        python -m pytest tests/integration_tests/agentic_workflows/ \
          --test-mode=${{ github.event.inputs.test_mode || 'ci' }} \
          -v \
          --tb=short \
          --disable-warnings \
          --timeout=300 \
          --maxfail=5 \
          -n auto
        
        # Live system quality tests
        python -m pytest tests/integration_tests/live_system/ \
          --test-mode=${{ github.event.inputs.test_mode || 'ci' }} \
          -v \
          --tb=short \
          --disable-warnings \
          --timeout=300 \
          --maxfail=3
      
    - name: Upload API test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: api-test-results
        path: |
          backend/pipeline_system_tests/test-results/
          backend/tests/integration_tests/test-results/
          backend/tests/integration_tests/live_system/test-results/
      
  # Emergency Bypass Job (runs instead of API tests when needed)
  emergency-bypass:
    runs-on: ubuntu-latest
    name: "Emergency Bypass Mode"
    needs: fast-tests
    if: github.event.inputs.emergency_bypass == 'true'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-xdist

    - name: Run emergency bypass tests
      run: |
        echo "ðŸš¨ Running in emergency bypass mode - API tests skipped"
        chmod +x scripts/ci_emergency_bypass.sh
        ./scripts/ci_emergency_bypass.sh
      
    - name: Upload emergency test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: emergency-bypass-results
        path: |
          backend/tests/unit_tests/test-results/
          backend/tests/integration_tests/test-results/

  # Job 3: Performance Benchmarks (optional)
  benchmarks:
    runs-on: ubuntu-latest
    name: "Performance Benchmarks"
    needs: [api-tests, emergency-bypass]
    if: |
      always() &&
      (needs.api-tests.result == 'success' || needs.emergency-bypass.result == 'success') &&
      (
        (github.event_name == 'workflow_dispatch' && github.event.inputs.include_benchmarks == 'true') ||
        (github.ref == 'refs/heads/main')
      )
      
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0 # Needed for checking git history in benchmarks

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
        
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run Benchmarker
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        PYTEST_TEST_MODE: "benchmark"
      run: |
        echo "ðŸš€ Running performance benchmarks..."
        make test-benchmarker

    - name: Upload Benchmark Reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-reports
        path: unified_benchmark_reports/

    - name: Generate test documentation
      run: |
        cat > TESTING_GUIDE.md << 'EOF'
        # ðŸ§ª VoiceTree Testing Guide
        
        ## Test Architecture Summary
        
        VoiceTree uses a 3-tier testing approach:
        
        ### 1. Fast Tests (< 60s)
        - **Unit Tests**: Isolated component testing
        - **Integration Tests**: Cross-module testing without API calls
        - **Purpose**: Rapid development feedback
        
        ### 2. API Integration Tests (< 15min)
        - **Real API Integration**: Tests with Gemini API
        - **System Integration**: Full pipeline testing
        - **Purpose**: Validate real-world functionality
        
        ### 3. Quality & Performance Benchmarks (< 20min)
        - **Quality Scoring**: LLM output quality assessment
        - **Performance Metrics**: Speed and efficiency testing
        - **Purpose**: Ensure production readiness
        
        ## Local Development Commands
        
        ```bash
        # Fast development testing
        python dev-test.py --speed smoke     # < 10s
        python dev-test.py --speed fast      # < 30s
        python dev-test.py --changed         # Test only changed files
        
        # Comprehensive testing
        make test-unit                       # < 45s
        make test-local                      # Limited API calls
        make test-ci                         # Full API testing
        
        # Watch mode for continuous testing
        python dev-test.py --watch --speed smoke
        ```
        
        ## CI/CD Philosophy
        
        - **Fail Fast**: Unit tests run first for quick feedback
        - **API Gating**: Real API tests only on main/develop branches
        - **Cost Control**: Limited API calls in local mode
        - **Parallel Execution**: Maximum efficiency with job parallelization
        
        ## Audio Testing
        
        Audio processing tests are excluded from CI/CD due to:
        - Heavy dependencies (Whisper models)
        - Environmental instability in containers
        - Resource requirements
        
        Run audio tests locally:
        ```bash
        python process_transcription.py --audio path/to/audio.m4a
        ```
        EOF
        
        echo "ðŸ“ Testing documentation generated"
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: |
          backend/benchmarker/quality_log.txt
          backend/benchmarker/latest_quality_log.txt
          backend/benchmarker/quality_tests/latest_run_context.json
          oldVaults/VoiceTreePOC/QualityTest/
          TESTING_GUIDE.md
    
    - name: Comment results on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: 'âœ… VoiceTree testing completed!\n\n**Fast Tests**: Unit + Integration (no API)\n**API Tests**: Real API integration\n**Benchmarks**: Quality & performance metrics\n\nCheck the "Actions" tab for detailed results and artifacts.'
          }) 