#!/usr/bin/env python3
"""
Test script for VoiceTree improvements - validates error handling, chunk validation, and content quality
"""

import sys
from pathlib import Path
from unittest.mock import patch, MagicMock
import pytest
import unittest

# Add the backend directory to the Python path
backend_dir = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(backend_dir))

from agentic_workflows.workflow_interface import WorkflowInterface
from agentic_workflows.schema_models import (
    SegmentationResponse, ChunkModel, 
    RelationshipResponse, RelationshipAnalysis,
    IntegrationResponse, IntegrationDecision
)

class TestVoiceTreeImprovements(unittest.TestCase):
    """Test suite for VoiceTree quality improvements"""
    
    def setUp(self):
        """Setup test environment"""
        self.workflow = WorkflowInterface()
        
    def test_segmentation_error_handling(self):
        """Test segmentation handles errors gracefully"""
        # Test with empty transcript
        result = self.workflow.execute_workflow("")
        assert result["current_stage"] == "error"
        assert "Empty transcript" in result["error_message"]
        
        # Test with too short transcript - currently this passes through
        # TODO: Add minimum length validation if needed
        result = self.workflow.execute_workflow("Short")
        # For now, short transcripts are processed successfully
        assert result["current_stage"] in ["complete", "error"]
        
    def test_chunk_validation_and_merging(self):
        """Test chunk validation and over-fragmentation prevention"""
        # Mock the LLM response with many small chunks
        mock_chunks = [
            ChunkModel(name=f"Chunk {i}", text=f"Text {i} content that is long enough to be valid", is_complete=True)
            for i in range(20)  # Too many chunks
        ]
        
        mock_response = SegmentationResponse(chunks=mock_chunks)
        
        with patch('agentic_workflows.nodes.call_llm_structured', return_value=mock_response):
            result = self.workflow.execute_workflow("A long transcript with many ideas and concepts that need to be properly segmented")
            
            # Should have merged chunks to prevent over-fragmentation
            assert len(result.get("chunks", [])) <= 15
            
    def test_integration_decision_fallback_content(self):
        """Test integration decision generates fallback content when extraction fails"""
        # Mock analysis data
        analyzed_chunks = [
            {
                "name": "Test Chunk",
                "text": "Some test content that should be processed",
                "relevant_node_name": "Test Node", 
                "relationship": "elaborates on"
            }
        ]
        
        # Mock LLM failure
        with patch('agentic_workflows.nodes.call_llm_structured', side_effect=Exception("LLM failure")):
            # Use longer test input that won't be filtered out
            test_input = "This is a longer test transcript that should be processed correctly by the system."
            result = self.workflow.execute_workflow(test_input)
            
            # Should return error when LLM fails at segmentation stage  
            self.assertEqual(result["current_stage"], "error")
            self.assertIn("LLM failure", result["error_message"])
            
            # But fallback should still create a chunk for further processing
            chunks = result.get("chunks", [])
            self.assertEqual(len(chunks), 1)
            self.assertEqual(chunks[0]["name"], "Voice Input")
            self.assertEqual(chunks[0]["text"], test_input)
            
    def test_content_quality_validation(self):
        """Test that generated content meets quality standards"""
        # Mock good integration response
        mock_decision = IntegrationDecision(
            name="Quality Test Chunk",
            text="Quality test transcript content",
            action="CREATE",
            target_node="Test Node",
            new_node_name="Quality Test",
            new_node_summary="This is a quality summary with sufficient detail",
            relationship_for_edge="elaborates on",
            content="‚Ä¢ High quality insight about the topic\n‚Ä¢ Actionable information with clear value\n‚Ä¢ Meaningful context for understanding"
        )
        
        mock_response = IntegrationResponse(integration_decisions=[mock_decision])
        
        with patch('agentic_workflows.nodes.call_llm_structured', return_value=mock_response):
            result = self.workflow.execute_workflow("Quality test transcript")
            
            # Validate content quality
            decisions = result.get("integration_decisions", [])
            assert len(decisions) > 0
            
            for decision in decisions:
                content = decision.get("content", "")
                # Should have bullet points
                assert "‚Ä¢" in content
                # Should have meaningful length
                assert len(content.strip()) >= 20
                # Should not be just the fallback
                assert "content extraction failed" not in content

    def test_workflow_robustness_with_partial_failures(self):
        """Test workflow continues even when some stages have issues"""
        # Test with mixed success/failure scenarios
        def mock_llm_calls(prompt, input_data=None, response_model=None, stage_name=None):
            if stage_name and "Segmentation" in stage_name:
                # Successful segmentation
                return SegmentationResponse(chunks=[
                    ChunkModel(name="Good Chunk", text="This is a good chunk with sufficient content", is_complete=True)
                ])
            elif stage_name and "Integration" in stage_name:
                # Partially successful integration (some missing content)
                decision = IntegrationDecision(
                    name="Test Chunk",
                    text="Test content",
                    action="CREATE",
                    target_node="Test Node", 
                    new_node_name="Test",
                    new_node_summary="Test summary",
                    relationship_for_edge="relates to",
                    content=""  # Missing content - should trigger fallback
                )
                return IntegrationResponse(integration_decisions=[decision])
            else:
                # Other stages succeed
                return MagicMock()
                
        with patch('agentic_workflows.nodes.call_llm_structured', side_effect=mock_llm_calls):
            result = self.workflow.execute_workflow("Test transcript with enough content to be processed successfully")
            
            # Should complete successfully with fallback content
            self.assertNotEqual(result["current_stage"], "error")
            # Should have some results even if not perfect
            self.assertIn("chunks", result)

    def test_minimum_content_requirements(self):
        """Test that chunks meet minimum content requirements"""
        # Mock segmentation with very short chunks
        short_chunks = [
            ChunkModel(name="Short", text="Too short", is_complete=True),  # Too short
            ChunkModel(name="Good Chunk", text="This chunk has sufficient content to be meaningful and useful", is_complete=True),
            ChunkModel(name="", text="No name chunk", is_complete=True),  # No name
        ]
        
        mock_response = SegmentationResponse(chunks=short_chunks)
        
        with patch('agentic_workflows.nodes.call_llm_structured', return_value=mock_response):
            result = self.workflow.execute_workflow("Test transcript content that should be properly segmented")
            
            # Should filter out invalid chunks
            chunks = result.get("chunks", [])
            assert len(chunks) >= 1  # Should have at least the good chunk or fallback
            
            for chunk in chunks:
                assert len(chunk["text"]) >= 30  # Minimum length
                assert len(chunk["name"]) >= 3   # Minimum name length

if __name__ == "__main__":
    test_suite = TestVoiceTreeImprovements()
    test_suite.setUp()
    
    print("üß™ Running VoiceTree Improvements Tests...")
    
    try:
        test_suite.test_segmentation_error_handling()
        print("‚úÖ Segmentation error handling - PASSED")
    except Exception as e:
        print(f"‚ùå Segmentation error handling - FAILED: {e}")
    
    try:
        test_suite.test_chunk_validation_and_merging()
        print("‚úÖ Chunk validation and merging - PASSED")  
    except Exception as e:
        print(f"‚ùå Chunk validation and merging - FAILED: {e}")
        
    try:
        test_suite.test_integration_decision_fallback_content()
        print("‚úÖ Integration decision fallback content - PASSED")
    except Exception as e:
        print(f"‚ùå Integration decision fallback content - FAILED: {e}")
        
    try:
        test_suite.test_content_quality_validation()
        print("‚úÖ Content quality validation - PASSED")
    except Exception as e:
        print(f"‚ùå Content quality validation - FAILED: {e}")
        
    try:
        test_suite.test_workflow_robustness_with_partial_failures()
        print("‚úÖ Workflow robustness with partial failures - PASSED")
    except Exception as e:
        print(f"‚ùå Workflow robustness with partial failures - FAILED: {e}")
        
    try:
        test_suite.test_minimum_content_requirements()
        print("‚úÖ Minimum content requirements - PASSED")
    except Exception as e:
        print(f"‚ùå Minimum content requirements - FAILED: {e}")
    
    print("\nüéØ VoiceTree Improvements Testing Complete!") 