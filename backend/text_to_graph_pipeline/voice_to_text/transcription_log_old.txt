Cool. Let's see. Do we have a log?
with I mean that would actually be in back end textograph pipeline voice text we want to see if there's a transcription log
and I don't see it to be honest
So let's ask why it's happening
okay there's a bug okay so we do have a transcription log that's good we do also have an error which is less good
so that's probably if there's you always need a defensive check
Let's just ask it in planning mode, what the hell is going on, so the problem we had was an dependent relevant node agent, the complicated logic, and what we actually really only care about is processing the target nodes.
So...
Alright, we are now once again testing Voicetree live, first thing we can do is just see how much of a delay there should be about 4 seconds after that moderate pause If not, something is somewhat wrong. It's pretty annoying when doing a live test with someone
If the text just doesn't fucking show up, isn't it?
All right, I think we should probably decrease the timeout for it to flush a little bit, so currently it's one second, that's why it's a bit problematic All right, I think we should do that
Let's try and make that 600 milliseconds. I feel like that's a pretty natural amount of pause
Hmm
Oh my god, I'm getting really tired I would like to eat a little lyrebird Oh my god, it didn't even write a motherfucking markdown document
Oh my god
Oh my god
Oh my god, save it to a markdown or I'm going to fucking cry
Please don't make me a sad, sad man Oh my god, it's getting so fucking slow, so fucking slow, I could be a little bro
Okay, clear, bug, bug
Ah, okay, what am I even looking at?
Is, is, are we even creating nodes?
For creating nodes no more.
Hey, you okay? Yeah.
I got lots of things.
$15
How are you both feeling? Terrible
Do you think it's just something you ate? Or is it a pretty day out? Should I go for a walk? Well, I mean it's pretty late now.
Getting a bit late for a walk. It is 9.15 and you just got something. Mommy got something. An uran notification. What is it?
Urra notification. A guru? Urra. What's that? My brain. So it's time to go to sleep.
That's what I put in your beans. They had special beans. High-protein beans. High-protein rice. Topo.
You see your mother's Sunday? And your sister? They're going out there. I can't take the car unless you're not still here. I'm not taking the car.
Well, I'll be there, of course. No. No? He's going away?
Personal well-being and daily activities. Is it food or weather? Going for a walk? Feeling terrible? Go to sleep due to notification?
My new symptom, what I wrote so far on empathy. I was so cute that they wrote back.
Such a great idea. Here's how you could organize it. Very clever.
Next time we go anywhere, let's get a new...
Oh yeah, it'd be nice to have fizzy water. Now can you hand me your bowl? Want any more?
How do you feel? Terrible. Oh, Elani!
I'm sorry you feel sick.
I'm sorry.
Okay, now I'm actually working on VoiceTree.
I'm doing a live test of the VoiceTree system while Ilan is reading, which is going to annoy Ilan to no end.
Okay, I just wanted to check if it worked.
And we got it.
I don't understand what happened with that thing.
I don't know, but I'll... I don't know.
It's like I made it worse by what I did.
You need to deal with it. You should call it a plumber.
Right, I'm working on the voice tree.
And we're in a really good stage right now. So, we have our Y Combinator deadline in about a week. And we want to make a pretty killer demo for the Y Combinator deadline. And currently our core algorithm is in quite a healthy state.
In our latest quality log.
Um...
We're getting 4.7s, which is really unheard of. Um... Really quite amazing.
I'm really impressed with that. I deserve a pat on the back for that.
Um, for myself.
Um, I think one really good fix we made was...
Um...
Um...
One really good fix we did...
...was changing to Gemini 2.5 flash instead of flashlight. That seems to have improved the quality a bit.
And a lot of things have just come together as well, like core prompt changes.
So that was cool to see that working in action.
Now.
We have the open question of how good our voice to text is.
And.
Sort of not only how good the voice to text is, just the general feel of the software.
Um.
And how...
...kind of reasonable it is.
And latency-wise as well.
All right, so it does seem like right now...
...um...
...that either the voice of text is too slow...
...um...or more likely...
...more likely is that...
...that the core algorithm is blocking the text-to-speech.
So we need to figure that out. That's the core problem right now.
Alrighty, okay, we are working on Voicetree today and we're doing some live testing of Voicetree because the overall goal is we want to be able to prepare a really good demo for Y Combinator. It can be a little bit hacky, but ideally it just works.
That would be pretty epic if it can just work without having to hack around too much in video editing. The problem we're just working on is that there's some Voicetree text issues.
So, we had some Voicetree text issues and I think what the actual problem was was that it was like a latency problem since one of the threads, one of the methods was blocking one of the other methods was blocking the Voicetree text method.
So, we want to see if that's still the case.
Okay, I'm going to rerun now.
few things we're seeing how good the voice to text is doing some live testing we know the benchmarks are really good but we haven't tested as much with live voice testing we want to make sure it's okay for it to be able to record a quick demo tonight
um
and we want to so generally test the latency
so we're getting an error which is annoying
Text algorithm. We want ideally less than a 4 second delay.
And we now have much more than a 4 second delay.
Alright, but maybe it's actually not that bad. Maybe there was just a bit of a cold start problem.
Alright, now the important thing is to test.
Hmm, and it didn't work at all.
Oh...
Okay, you know what?
Um... I mean...
Mm-hmm.
Mm-hmm.
Bye. Bye.
Where do you want to get the charger? Yeah, right here.
That's a cool thing, man. Oh, food. Protein. Food, protein.
Now I'm doing a live test of voice tree, a live test of voice tree, a live test of voice tree, a live test of voice tree, a live test of voice tree, I'm trying to see how long the overall delay is.
It's about nine seconds, and now we want to see...
Now, where did you put the battery? The battery.
I want to see if it can work while the buffer is running.
I want to see if it can work while the battery is running.
w h a w h a tts no not tts what's like what's like what's
like w h a t yeah how was dinner um web dot what's that one p
two p's like an app huh like an app yeah you want an application on your phone what's w h a t s s whatsapp dot com dot com that's what i put in it said can't reach
qr code yeah so now you have to go on your phone
so make everything easy
okay on my phone and then
yeah yes I go into your phone now and go on to whatsapp
so I'm showing dad right now how to get whatsapp on his computer
yeah okay so go on to whatsapp and now in settings
yeah and now look at your computer yeah does it tell you what to do QR code
or whatsapp app yeah does it tell you what exactly to do go to settings
I'm in settings yeah and what does it say on your computer
so the QR code or whatsapp app yeah or whatsapp browser those are three things domain is for sale
okay dad let's work on it again spelling whatsapp
ok steps 11 open whatsapp on your phone got it do you download it first download it then you have it on your phone
let me get my glasses you're right
and i have to keep it on the sock i bet it was
freya
yeah
Okay then, we need your face I need your face You need my face, okay
You need your face, okay?
Have as much coffee as you want tomorrow
Let's roll this out This is pretty
Yeah, I got it on your computer now, Dan Perfect So that woman's email and her WhatsApp TV will come up, right? Yeah, it's there Be careful Jeff, you don't want to be overly friendly and starting a big conversation Of course you'll be willing to send it, okay? Ask her question
No Just answer And it's actually better for you not to answer right away, Jeff
Cause you're saying you're exhausted It's much better for you to wait till tomorrow Or not even reply It's three messages down, Dan But I agree with mom, I don't think it's a good idea to actually reply Well, it's like three or four messages down
Well, I just tell her about our employer I agree that it's better not to do it the same day
Unless you want to be buddy-buddy with her No, I don't mean buddy-buddy, she asked me a legitimate question, I want to answer it, not sure Yeah, but you don't want to be nice to her, you just want to answer the question And not on a Saturday, but on a Monday
That shows a bit of limit
Do whatever you want
That's very kind of you, thank you
Thank you
Thank you
Multi threading
All right testing one two three
You
All right, so think
actually start listening doesn't help.
All right.
Testing one, two, three.
So we have about an eight-second delay.
All right, I'm going to turn off.
Um, everything to do with VAD and see if that helps.
Alright, cool. We've made our model
Hello, hello, hello.
Alright, we've made our model more aggressive.
Rest.
Alright, now we're down to about 5 or 6 seconds, which is a big improvement from 9 or 10.
However, one of the problems is that we're now seeing a few more...
...um...
...possible transcription errors? I'm not really sure.
Okay, um, it actually looks...
fine for the mean time, at least for our...
uh, requirements...
um, definitely a lot more like...
type stuff.
Um, which isn't ideal, but it is okay. It's okay. It's okay.
Let's see.
Um, so let's test.
Um,
testing one, two, three.
Okay, so now we're seeing that it can end up with a real backlog.
Okay.
Okay.
<Queue maxsize=0 _queue=['Yeah, put it together.'] tasks=1>
<Queue maxsize=0 _queue=['We did it together.'] tasks=2>
<Queue maxsize=0 _queue=['Oh.'] tasks=3>
<Queue maxsize=0 _queue=['Testing one, two, three.'] tasks=4>
<Queue maxsize=0 _queue=['Testing one, two, three, four, five.'] tasks=5>
<Queue maxsize=0 _queue=['Well, okay, this might be really quick for us to text.'] tasks=6>
<Queue maxsize=0 _queue=['Well, this might be really quick for voice to text.'] tasks=7>
<Queue maxsize=0 _queue=['Well, this might be really quick for voice to text.', 'Put the picture in here.'] tasks=8>
<Queue maxsize=0 _queue=['Well, this might be really quick for voice to text.', 'Put the picture in here.', "Okay, thank you. We'll do..."] tasks=9>
<Queue maxsize=0 _queue=['Well, this might be really quick for voice to text.', 'Put the picture in here.', "Okay, thank you. We'll do...", 'Okay.'] tasks=10>
<Queue maxsize=0 _queue=['Okay, a few times.'] tasks=11>
<Queue maxsize=0 _queue=['Okay.'] tasks=12>
<Queue maxsize=0 _queue=['Okay.'] tasks=13>
<Queue maxsize=0 _queue=['This is the green jacket as well.'] tasks=14>
<Queue maxsize=0 _queue=["Alright, we're basically testing how good the boistertex algorithm can be."] tasks=1>
<Queue maxsize=0 _queue=['I have a beam size of just one.'] tasks=2>
<Queue maxsize=0 _queue=['and how much faster it is.'] tasks=3>
<Queue maxsize=0 _queue=['okay so maybe they are...'] tasks=4>
<Queue maxsize=0 _queue=['maybe the problem is mostly just the model.'] tasks=5>
<Queue maxsize=0 _queue=["Well okay so let's see now I guess..."] tasks=6>
<Queue maxsize=0 _queue=["Well okay so let's see now I guess...", "Yeah I don't think beam size of one is good enough."] tasks=7>
<Queue maxsize=0 _queue=["Well okay so let's see now I guess...", "Yeah I don't think beam size of one is good enough.", 'We want at least...'] tasks=8>
<Queue maxsize=0 _queue=["All right, right now we're just testing how much a"] tasks=1>
<Queue maxsize=0 _queue=['a beam size of four takes to respond.'] tasks=2>
<Queue maxsize=0 _queue=['About six seconds.'] tasks=3>
<Queue maxsize=0 _queue=["Okay, now we're going to change that to distill LH3."] tasks=4>
<Queue maxsize=0 _queue=['Testing, one, two, three.'] tasks=5>
<Queue maxsize=0 _queue=['All right, testing, one, two, three.'] tasks=1>
<Queue maxsize=0 _queue=['So distilled large V3 seems to be about the same as'] tasks=2>
<Queue maxsize=0 _queue=['the super'] tasks=3>
<Queue maxsize=0 _queue=['Turbo model.'] tasks=4>
<Queue maxsize=0 _queue=['Actually, I think it does look a bit faster.'] tasks=5>
<Queue maxsize=0 _queue=["Yeah, it's about."] tasks=6>
<Queue maxsize=0 _queue=['four seconds instead.'] tasks=7>
<Queue maxsize=0 _queue=['four seconds instead.', 'Okay.'] tasks=8>
<Queue maxsize=0 _queue=['four seconds instead.', 'Okay.', 'Um.'] tasks=9>
<Queue maxsize=0 _queue=['four seconds instead.', 'Okay.', 'Um.', 'A, B, C.'] tasks=10>
<Queue maxsize=0 _queue=['four seconds instead.', 'Okay.', 'Um.', 'A, B, C.', 'Four to six seconds.'] tasks=11>
<Queue maxsize=0 _queue=['Technic coffee to treat it had been made fun to be fun to you.'] tasks=1>
<Queue maxsize=0 _queue=['Oh.'] tasks=1>
<Queue maxsize=0 _queue=["I'll do it, I'll just give one more chance to test this."] tasks=2>
<Queue maxsize=0 _queue=["I'll do it for you."] tasks=3>
<Queue maxsize=0 _queue=['What is the latency after this?'] tasks=4>
<Queue maxsize=0 _queue=['Wow, okay, four seconds that might make it good enough.'] tasks=5>
<Queue maxsize=0 _queue=['and see when it ends up talking about chewable orange, flavored vitamin C dietary supplements.'] tasks=6>
<Queue maxsize=0 _queue=[', you know,'] tasks=7>
<Queue maxsize=0 _queue=['...'] tasks=8>
<Queue maxsize=0 _queue=['I know if you want to do it now.'] tasks=9>
<Queue maxsize=0 _queue=['Testing one, two, three.'] tasks=10>
<Queue maxsize=0 _queue=["One of those things, yeah. I don't know. That's really weird that for some amount of time..."] tasks=11>
<Queue maxsize=0 _queue=["One of those things, yeah. I don't know. That's really weird that for some amount of time...", 'It does seem like that was what was happening.'] tasks=12>
<Queue maxsize=0 _queue=['Yeah.'] tasks=13>
<Queue maxsize=0 _queue=["Yeah, I think I can't see how it could work."] tasks=14>
<Queue maxsize=0 _queue=['Yeah.'] tasks=15>
<Queue maxsize=0 _queue=['testing one, two, three.'] tasks=16>
<Queue maxsize=0 _queue=['What does it like to be me? Testing one, two, three.'] tasks=17>
<Queue maxsize=0 _queue=['What is it like to be me?'] tasks=18>
<Queue maxsize=0 _queue=["Hello, hello, what's your name?"] tasks=19>
<Queue maxsize=0 _queue=['Testing one two three.'] tasks=20>
<Queue maxsize=0 _queue=['Testing one two three.', 'Voice check.'] tasks=21>
<Queue maxsize=0 _queue=['Testing one two three.', 'Voice check.', 'All right, what are we going to work on today? We could eat cherries or berries or plenty of fairies.'] tasks=22>
<Queue maxsize=0 _queue=['What is?'] tasks=23>
<Queue maxsize=0 _queue=['testing really quickly.'] tasks=24>
<Queue maxsize=0 _queue=["Oh, so maybe what happens is that we made the total time up really too long, and so now it's detecting silence and then not really figuring it out."] tasks=25>
The test we're trying to do today.
is if we talk really slowly.
And if not, why not?
So I think.
We might just not be sending enough text at once.
If.
All right, I'm thinking that.
We don't really.
want.
make our voice a text.
So complicated.
For the reason.
that it's not really.
Very testable.
All right, so now if I keep on talking for a long amount of time...
the voice to text algorithm.
buying a new pair of shoes.
If I talk about all of that very quickly.
that's just mrs.
And that would be very sad.
So yeah, that is the thing is that I worry.
But this is really the sort of thing that it seems I just need to figure out myself.
So then the test for that would be that if we keep talking very quickly it was able to pick up every single word.
All right, so now what we are trying.
to do, I guess.
Vitamin C is a dietary supplement.
And then also if we just keep on talking for a really long time talking about all the apples and bananas in the world and the people and breathing and how all the things we do in our brain
Okay, so we're doing a real true test of voice tree right now
And we're just gonna talk about some of the things we need to work on today tomorrow actually it'll be good it's a good midnight it's a good time to
All right, cool. We are now going to see how robust voice tree is.
So we're going to run it on our voice to text algorithm.
and we are going to see what sort of notes are appearing. We're going to see if there's any failure cases in the voice-to-text model.
There's been a lot of recent problems with voice a text.
It's just complicated code and
lots of little small things that can go wrong. There were some problems with the internal model. There's been some parallelism problems and other things like that.
So we really want to see especially while we're creating new nodes
if we can continue to be processing.
And also I guess what we want to be thinking about is
if
if we should be starting to think if we can use a large model.
That's a really good question. So if we want to be able to use a large model for higher accuracy, that is one question. But we also just want to see in general if we speak
if we speak loud enough and clear enough is a medium model fine.
because the cool thing about a medium model is that a medium model can
actually handle us live on my computer.
he can do voice to text.
in real time.
which is quite neat.
Okay.
Now I'm also just noticing one problem with the voice tree application in general.
which is.
that.
Okay.
So I'm also noticing right now with the buffer.
the main flow of the algorithm.
is a bottleneck.
I can't be running fast enough.
And so we do have a few options there.
we can
delay optimization
is one option.
So we can only, that option would be only running the optimizer.
if
the
Um.
only running the optimizer if
We haven't had another append, like you have like a five second window to see if we get another append.
And if there's no pen, then we run optimizer.
But that's a lot of complexity and could go wrong very easily.
Another option is, is that we just increase our buffer size. Increase a buffer size means we're just sending less LM calls.
which might mean that we could maybe just with a very small buffer increase we could get away with it.
Okay, let's go with doing the quick fix
by increasing buffer size.
And then we can do some deep planning to see if we can have a bit more parallelization or smart optimization delays.
or like sort of a sync calls to see how else we could speed things up.
Okay, another cool option.
for decreasing the total latency.
is we can have.
Um,
So what we can do is we can have
Some of the prompts run a
So for example we know that segmentation
isn't really that important.
We can have a really cheap model run segmentation.
Um...
In fact, maybe segmentation isn't even really necessary.
Hmm.
What is the point of segmentation currently right now? Let's think.
Let's have a look at the actual prompt for segmentation.
and see what it's being used for.
and what the complexity of the thought is.
Oh segmentation has to be able to finish and or unfinished content.
That's the complexity of it.
So it's our arbitrary chunk.
boundary solution.
What am I doing right now right now? I'm looking at the debug logs for identify target node to see if we if decreasing transcript history would make a difference as well.
And I just noticed that there is a nice problem of transcript history, which is that it doesn't start.
I can cut off a word in the middle.
So that's not very good.
How many nodes are we at now?
So we're at 13 nodes.
Let's see if.
We're choosing the right nodes.
Nice, okay we are.
hmm.
Okay, so well let's have a look at our voice tree.
So we have low cost segmentation strategy. Yeah, that's decreasing using the cheaper model for segmentation.
That's a good one
And then we have.
voice tree buffer size increase. We've done that that's done
Okay.
So what's the current situation where can we currently set the model from setting a cheaper model for a certain prompt?
So that's in
core agent.
I think I'll have integration.
in
in a single
Optimizer.
Hey.
Easy.
Okay.
And now I'm realizing actually what we want.
is a dynamic buffer size.
whereby
So this is quite complicated logic.
So inner main dot pie.
as we're getting audio.
and then
add that audio right?
to a buffer.
once we've processed it
So we put that into a text queue.
And then?
we take from that text cue.
and then
What ideally want to be able to do is build up.
a bit of a buffer.
But I think the current problem is what is the current problem wasn't it currently work
So you currently process.
and then you're processing most of the time.
So as you go back.
The buffer content maybe hasn't been added.
So one problem is we don't have a buffer full log.
so it seems.
would be good to have a buffer full.
Okay, let's go add that to work.
So that's gonna be in.
So we have
What do we do right now? We're adding a log.
to know when the buffer is full.
So we can get some idea of understanding of the
how to optimize dynamic buffer links.
because ideally it should happen implicitly.
Okay, so where is that in buffer manager?
So we have buffer manager dot pie.
I can just search for.
I think we found it.
Let me say starting Steve.
Okay.
So
the next steps for this.
ideal buffer, dynamic buffer solution is when you look through the logic and main. Pie and trace it out and understand why currently it isn't actually a really dynamic buffer.
Ideally what we want is.
I mean if it's really slow in running, right?
Let's just walk through this. It is really slow.
So if it's really slow.
then
So we have.
process new text and update Mark Doom.
And then we should say.
Got text from Q.
So, okay, let's just talk really quickly and talk about like 10 different things at once and my headphones and my car and my Apple and my computer and all the things I want to do. I want to go to the gym tomorrow. I want to go to the gym tomorrow. I want to go to court tomorrow. I want to look at art tomorrow. I want to meet Freya tomorrow. I want to hang out with my dad tomorrow.
So many different things I want to do, right? And so what should be happening right now is that our buffer should be accumulating in May end up high? Because in the background, we are doing all this voice to text transcription, right? So what we should end up with is like one huge buffer where the next time we run our LL processing loop, it is...
Alright, like i mean that's what's gonna happen?
Okay, so this is cool. So the buffer is full, sanctogenic workflow, and then what should ideally happen is that the next time it comes around, it should have a really, really, really big loop handle, right? Like, I mean, that's what's going to happen.
is the next time it comes around from the appending.
It's just going to have like this really really big huge buffer
So let's see if that's what actually ends up happening. Because right now...
Okay, so dynamic puff buffer actually does kind of work.
which is pretty epic honestly so what we've realized is that if we do talk really quickly from this little test
that we've just been doing. If we do talk really quickly, then it is actually able to have a buffer sort of overflowing.
and then the buffer just gets bigger and bigger, which is fine.
So it's sort of.
returns back to normal automatically. It's like self.
I'm a self-balancing buffer.
Let's want add one other thing which is like part of dynamic buffer let's have
The buffer be dropped by half just for the first execution.
Okay, and now we're going back
idea to have the low cost segmentation strategy.
of just being able to run a cheaper model.
We've now implemented the code to be able to do that. An agent working in the background.
Now we're just going to implement what they've done. So let's just quickly look at what they've.
written.
looks about right, just piping things through.
and then
We'll add to our
Agent, so penned node node agent.
So segmentation we can do with it cheap.
If I could know it would want a bit more expensive.
Okay.
We might know we can maybe just run
Um.
the
So.
Okay, let's first just commit our changes.
Okay, cool. I'm realizing a few things right now, just looking through the voice tree.
So I'm looking at a graph.
things we've been talking about recently.
and I'm realizing a few things.
One of them is that we can make identify target note a bit more aggressive.
in choosing nodes that.
Like any good relationship? Well, I mean...
is actually better not to force relationships.
and then better with the full understanding later to come back.
and re-evaluate if it should be connected to the wider tree.
Okay.
Cool.
The other thing I was thinking.
was that.
Huh.
Um,
Um.
Okay.
Okay, yeah the other thing I was thinking about
was the fact?
that ideally we can have our optimizer run non-blocking.
It can be running
text is appending.
No, no, that's just a recipe for disaster, isn't it?
Oh, fuck I don't know.
So I was thinking that.
The nice thing is is that we can have
You see the note appear.
Optimizer could run in the background.
But for now it's just unnecessary complexity.
Okay, so I guess the main thing I was trying to figure out.
Right.
was
if
I guess is can it now handle our rate of speech right so that was the original problem we're trying to figure out is if we're talking to voice tree consistently can it handle our right of speech?
Or is it a bit too fast a rate of speech and the system gets backlogged?
And if it gets backlogged, how are our capabilities for handling the backlog, etc, etc.
So I would say.
that this is what we want to know right now.
Okay, and so based of rate of speech handling
we're essentially trying to see.
So one thing we're doing with that.
is we're doing a live test right now of voice tree speech rate handling and we're seeing how that live test is going. So that's one specific node.
uh...
another specific node.
another specific node...
off of voice tree speech rate handling.
off of voice tree speech rate handling.
is understanding what optimizations we can make.
is understanding...
to improve voice tree speech rate handling.
The thing is that if the live test shows that our current system...
And the thing is that if the live test shows that our current system can handle the amount of input we're giving it, well then that means that we don't actually need to optimize further. We're chillin.
So that is a very interesting question. So right now, it's entering a live test.
We can look back
the logs in the live test.
Right.
and see.
Uh huh?
what it's like.
what it's...
And unfortunately it does look like.
that we're still getting a fair bit of a backlog.
that was still getting a fair bit of a backlog.
So maybe we need to do it now, but with like, um...
So maybe we need to do it now, but it with like,
Well, really it's performance engineering, really isn't it?
We need to be able to see.
Okay, and then there is one completely different solution for optimizing the latency of Voistree.
which is we could
which is...
instead of doing a buffer approach, we could do segment by segment.
and ask at each segment.
and ask at each segment.
Hey, is this segment done?
Hey, is this segment done?
If so send it and route it.
If you're
If not.
if not
That does come with a lot of problems around not knowing the surrounding context.
But that does come with a lot of problems around not knowing the surrounding context.
Unfortunately.
optimizer, okay, let's do.
Let's change all our logs.
we could also.
Heh.
Just flush buffer.
Okay.
Okay.
I can't believe how mean Snuffles got just because he's smart.
Oh, I'm
No, everyone actually believed me.
So much better than standing up.
Lieutenant General, who do you want to save the pilot or the troll? Oh man, I feel bad.
Is that to happen, right?
my chutea.
Pappu.
Nate and Missy like each other.
All right, Caleb.
wrong.
He might like her, but her heart belongs to me.
What are you talking about you wanting me to be here with you? You said you needed me. You stroked my arm. People saw that. We're getting married, right? Jump in any time. Well, I, I do like you, but only...
I have romantic feelings for you, too.
You see what's happened?
no, that she ever did.
You're still thinking about Camden? Hunt stower his phone like a dirty gargoy. I know I. See in the world I hate. Jesse, all guys.
Maybe.
Frankly,
Can't stop door. Shut the fuck up, love!
so hard to you last night. Weirdly, it kind of does. I woke up in my kitchen.
Oh, I give you.
There, my little gay prince.
Let Dwayne find it.
I can't believe I'm about to say this.
But I know, it's stupid, stupid hormone monster goat man. I was going to say that's a great idea. It is? The thing I said? Yes.
Hey, Dwayne.
. You.
I'm still figuring it out. Oh, Sand, huh? Oh God, he's calling you. Oh, no, how's my hair? Perfect as always. Hey! Hey! I'm so glad you said that. I feel the same way. Really? You?
Yeah, I'm not the only one.
Now, my anaconda don't. My anaconda don't, don't. My anaconda don't.
this is...
because you're such a bitch.
You're fucking deaf.
I rule that school.
Right?
You eat shit and die. Remember who you are, Devon.
Fisne do this.
You can't.
You can fucking do this.
It's Showtime.
Shaim are you damn for you have lying to us all
of them. I'm actually quite delicate so you know what I've decided that yeah this is all Devon's fault. That's right story. If she hadn't told everyone about what happened then I wouldn't have had the lie oh please you
you're gonna get revenge
and I scored a hug with a hug and I scored a hug with the booty that won't quit exactly so from now on no more missis nice missi I guess I could stand to be a little more selfish
you're
uh... what do you doing here looking for coco the compassion pecad you she quit compassion yeah years ago something about fuck humanity and she's sick of the parking garage here anyway i use your office as uh...
hold it's a thing that i did for fun that's my hobby i like it since when
Alrighty, okay, cool.
So today we've made some really awesome progress with the target node prompt and the optimization prompt.
I think we did go a little bit in circles on the optimization prompt. We fell into sort of LLM trap.
Um
where we just sort of went in circles with the LM not actually properly truly understanding what I was talking about.
which was a little bit unfortunate but sometimes that's how it is
Okay.
No.
I think now that the core algorithm is pretty sound we managed to get an excellent score on our benchmark. We really need to pivot, very important, we have to pivot to just making sure it is demoable.
That voice tree the project we're working on is demoable
and some things we want for that demo ability.
Um
is we need
to have a little mini UI I think
Um
A mini UI would be good. We need to have sort of like a good general approach for using Voic Street. So sort of start more general, so you have general nodes to attach to. That's one example here where it failed where project demability focused that node became an orphan even though it's related to the overall voice tree project but we didn't have a node for the overall voice tree project so if we start more general and get increasingly more specific at least for demos
we avoid that problem. Cool. One other thing I wanted to try out was...
Um,
symbols, so I know that
There's certain symbols that we can use to represent our nodes, icons.
And we wanna see.
what that does really.
Um
And then the main problem I'm going to have for the demo, I think, is the current animation of the graph. The animation of the graph is really annoying. Whenever we add a new node, it completely just spawns a node in almost like a random location very far away. And then like two or three seconds later, the graph refreshes and everything sort of jumps around to a new format. We need to keep nodes in their existing locations so nothing changes. existing locations, so nothing changes very often, except the new nodes, and the new nodes we want to appear in a reasonable spot at first draw.
So that as you're showing the demo and the nodes are appearing on the screen, it looks like a tree is growing rather than chaos.
Oh cool. So one call I have idea for demoing voice tree with the sort of structured approach is it's really cool if I outline the key components of voice tree.
like what voice tree is what the nodes are things like that and then those show up as entities on our graph
And then any further discussion of anything to do with Voicetree gets a pen into those nodes. But the main cool thing about this is that for the demo it serves as documentation itself. So I'm explaining Voicetree.
and what it is. The person who's watching the demo gets to understand, but now it also helps the actual demo itself because there's nodes to attach to.
you're
I'm trying now also the agenda component of our demo and I think it's fine I don't think we should overly
It's cool enough. I don't think we need to worry too much about things like the node placement, but definitely if we can.
Um...
There is now also the idea of making like a synthetic parent node. We've talked about that a bit before. I mean that would avoid this key problem where everything's sort of referring to a parent node that just doesn't exist and so there's nowhere to attach to.
and so maybe we need to make synthetic.
parent nodes, and maybe we can change our routing algorithm to instead make an orphan synthetic parent topic name. Cool, that's a really good idea.
And we also need to include relationships and our inputs for the...
target node.
You can start talking? So I'm going to be discussing my job, which is humanitarian aid operations in Afghanistan.
for DG echo the European Commission. We are... You don't need to have annoying... You don't need to pause weirdly. You can just speak normally. But I don't see it doing anything. Well, yeah, because it... just you just go talk for a while.
It's not very real time.
So we're doing humanitarian aid operations in Afghanistan. We're funding multiple different
actors, NGOs and UN agencies, and I want to get an overview of the proposals we've received to decide how to allocate funding to the various... There's no more rivals.
I made you a special yogi tea for women.
This is why you need a pause one.
Oh.
So what I'm trying right now is a new technique where we use very low buffer sized thresholds to flush
And we want to see.
how that sort of ends up working where if we have very low brother size thresholds, what becomes the actual behavior of the...
system.
So
Ah, okay, so one thing we've noticed right now is that there's no actual
outputs from that which is fine.
until you run it a few times so segmentation therefore is working
So we'll continue to do a live test of with low buffer-sized thresholds to see if it increases the overall reaction ability.
Oh.
And it does actually seem to.
help.
which is quite interesting.
So we'll just have to see what the overall buffers end up being and how much of a lag we build up and whether that's fine.
Okay, I'm Ilan Mason. I work for the European Commission and I work on humanitarian aid.
for
Taekwondo for Afghanistan and right now we have a large problem where America has taken away all our funding and so we're sort of dead in the water scrambling to figure out what we should do and so I'm going to spend some time thinking about how to approach this hard problem of aid in Afghanistan.
I should I bring you a tea? No, I'm okay, thanks.
Really?
Did you already give it the introduction?
No, you got to give it your introduction.
I am working on, how do I see the U. I am working on humanitarian aid operations in Afghanistan for DG Echo at the European Commission.
We are a donor and we fund actions in the country and I want to use this voice tree to help me decide on funding allocations.
and on decisions in what projects we should fund this year. So I've received some funding proposals from United Nations agencies and some from NGOs and I want to distinguish between
the different proposals putting information in each note about what they have to help me make visual to use as a visual guidance for decision-making processes Let's start with the So the idea is you press command press command and then you can read about what you've actually said here
You command and then you hover over it. Oh, I don't even fix one thing. I love it. I can just fix it.
Is it? See, look at what you've already said. And you press command and you hover over it.
And then it gives, you know, it just a brief summary of what that actually is. And then you can... And does it have the same knowledge as Claude? Doesn't know? Yeah. About like...
But it's only like summarizing what you've been saying. So let's start with one funding proposal that I've received from the World Food Program.
this is requesting 30 million euros in funding for us to respond to
food security needs across the country in almost every single province and also targeting retourneys from Pakistan and Iran, which is positive.
Then we also have a proposal from the NGO International Rescue Committee, IRC, asking for 10 million euros of funding to work on health.
food security and protection all of which are very important sectors
Then we have a proposal from Save the Children requesting five million euros in funding for health care and protection and education in emergencies
or the other ones. Yeah, where's nine?
Oh wait, just, hang on, click on this?
There should go.
Okay, so it's making them as like orphans, which is one common problem.
So it made those nodes as an orphan. I can link it, right? You could link it, yes. He's write the node, the name of the node.
But it would then be useful if I could upload the proposal into here and then it would summarize it for me.
Can I already do that? Yeah.
You can.
Um,
So yeah, right now the UI is very junkie as you can see
But I'll give you an example of how you would do that. Yeah, can you show me a proper voice tree? I want to see like a really build-up one so you must have some examples.
I'll show you what you could do so if you wanted to
you could
So let's say one of these, funding proposals, right, you could edit, edit here. So you can go edit, right, and just on the graph.
You can say, here are, here is paste of docs.
right? And then on that node
So here you can go, you can hover over it and you can edit it or you can say whatever you want. But you did get rid of the...
Anyway, let's just say we edited it and then we can open our terminal.
Okay, now we have a terminal, so I know that the graph is like flickering, that's why I need to fix that. Anyway, now you have a terminal connected to it. Cool, and then I could ask questions. And you can open the terminal just like this, you can hover over it, and you can, so right now I don't have it.
So I can go Clyde to S.H.
So we sort of skip some of this in the demo, right? But now it's working and you can ask it.
Do you want to ask you a question?
and
again right the point is is not that it's currently useful for you the point is that currently we have the components my god it's impressive money to make a demo that shows it would be really cool
that shows it'll be really useful. This is pretty impressive.
My know, this is really impressive what it came up. Yeah.
That's useful for me
Yeah.
I mean I should spend an hour speaking to it. I could really use this for my job.
Yeah.
Can you show me a voice tree that's complete?
No, I keep deleting them. Why?
You can start saving them, very cool I know.
And what was the benchmark test you said? Yeah, it doesn't matter.
A large language model. So one of the biggest issues at the moment in Afghanistan is the ongoing forced return of millions of Afghan citizens from Pakistan and Iran.
I ran out of my phone.
Sure.
being in a park.
So cool. You did it.
All right, today I am working on Voistree.
our voice to graph project.
and I want to be able to demo it very soon. So I only have a few hours, three hours, and I really want to be able to demo it.
to my brother's friend. My brother's here right now.
Um, and
Oh.
We need to figure out what are the things we need to do for the drip demo. So one, the first thing is we need to do a live test right now of Voice Street to see how well it's working.
And then based off that would say to work some of the problems are.
Um,
So unfortunately one of the problems I've been facing is that I've been working a bit sub-optimally where I keep on changing things in the project.
which then leads to three other issues. So I'll solve one problem that just creates three hours because the complexity spiral.
So I need to avoid that from happening. So I think I need a decision here is to just completely stop editing the core algorithm. We only have a week till the YAC combinator demo that we need to do.
And so I think the core algorithm can have some minor fix up, but we don't want to do any major changes to the prompts anymore.
Um,
Okay, and then within this current demo, one thing that I'm realizing is that we need to improve the graph animation. So currently nodes appear in like a weird position, and then the graph refreshes.
and we don't want that to happen.
um
It
really disrupt the user interface and flow.
um
So, yeah.
Okay.
Okay, the other thing I am seeing wrong with the prompt is that
Um,
the we
Our buffer is accumulating very long.
because our complete algorithm is not fast enough.
So we need to improve the speed over.
core algorithm. We have some different options there. One option is to use a smaller model.
The smaller model for the LLM will be faster, which means we get faster responses, which means we won't get a backlog of a buffer.
Cool. Okay, so we have that smaller LM model for speed improvement.
um
that could help the algorithm buffer accumulation problem.
And then what else do we need to do for the demo?
Oh yeah, improving voice tree graph animation. So what we need to do there is the first step is we need to look into the obsidian juggle plugin, the one that I'm using, and we need to
uh...
improve.
the logic for when a new node is automatically added to the graph
So when a new node is added to the graph.
We need to change the logic there to do a better reset of the graph or perhaps not reset the graph.
We are noticing like a two to three second delay.
Um,
Cool.
Um,
Cool. Okay. Let's get an agent to work on that.
So we have our terminal now.
Let's open it and we'll run into Quad.
Okay, nice, while that's running in the background.
It has access to all our files. I'll see what else I can work on.
Um,
So upcoming Y-Cominated demo, that's our larger goal. So this demo that we're doing right now is just to practice for the Y-Cominer demo.
And for the Y Combinator demo,
Um,
We want.
to
I think we want three different types of demos so we want this style demo where I'm doing sort of software engineering type work
and
we want also.
a demo of a meeting because I think this can improve meeting efficiency a lot.
And then we also want to demo the whole flip side of this project, which is actually improving ELLM performance itself.
And so I'll sort of show you what I mean by that. So right now, as you can see in the background, our agent is working on this graph reset delay on node addition problem. And it's sort of exploring the solution space and adding nodes. And so I'll have a visual understanding, so I'll pause it right now, a visual understanding of the solution it's building.
And then I can also give it feedback for example, so full access to the agent here.
I'm
and
then
So let's have a look at this white column and that one.
So this problem we noticed there was that the
It's just taking a bit too long, right? So we have.
Oh.
Okay, so what happened here is that.
the, so there's one node for upcoming YComo demo.
Um,
And then there is another.
demo.
Oh.
And then we have a meeting efficiency demo.
So that's interesting is that it didn't make these at the upcoming YCometer demo. It made these more the Voice Tree Project demo preparation, which is reasonable, but I do need just a way to know which node is the most recent. So I can open the file switcher here, or I can...
Color the more recent nodes I made, maybe color them in blue, the last three nodes that I made.
or add the numbers to the title. So I'll ask Elon what the best option to do there is to make it obvious what nodes were recently modified.
So for example 13
need for most recent note indicator.
I'm now starting to find exactly where it is up here.
Um,
Oh.
And then.
Yes, and now that once the graph becomes about a certain size, we really need good organization.
Um,
is also
Let's see and we also have this other
Hmm.
Where actually is that note? Legit can't find it.
Cool. Okay, now we have that smaller LM water receipt improvement. That could help the...
the algorithm population problem. And then what else do we do with the demo? Oh yeah, I'm proving voice tree graph animation. So what we need to do there is the first step is we need to look into the obsidian juggle plug-in that I'm using and we need to...
improved.
the logic to when a new note is automatically actually grass.
Yeah.
Cool. Okay, so we have that smaller L&M water speed improvement. That would help me.
the algorithm population problem. And then what can you do for them?
improving industry graph animation. So what we need to do there is the first step is we need to look into the Obsidian Juggle plugin form that I'm using and we need to...
improve
Cool. Okay, so we have that smaller LML literacy improvement. That would help the...
the algorithm buffer accumulation problem. And then what else do we do for the demo? Oh yeah, I'm proving voice tree graph animation. So what we need to do there is the first step is we need to look into the obsidian juggle plugin one that I'm using, and we need to...
improve the logic for when a new node is on the actual grass.
Cool. Let's get an agent to work on that. It's automatically out of the graph.
Cool. Okay, let's get an agent working out.
We have our terminal now, let's open it.
logic when a new nose is on the actual ground.
Cool. Let's get an agent to work on that.
the logic when a new nose is automatically actually grass.
Um,
is the first step is we need to look into the obsidian juggle clone one that I'm using and we need to
improve the logic of when and you know is on the actual grass.
and you know it's on the actual graph.
And you know it's automatically actually breath.
Okay.
Cool. Let's get an agent working on.
We have our terminal now.
Okay, well that's running in the background. It has access all other files. I'll see what else is more done.
So upcoming Y-combinator, that's our larger goal. So this demo is just a practice for the Y-combinator demo.
We want to
I think you want three different types of demos. So we want this style demo where I'm doing software engineering type work. And we want also a demo of a meeting. So I think it's gonna improve meeting efficiency a lot.
And then we also want to demo the whole flip side of this project, which is actually improving the elements itself. And so I'll show you what I mean by that. So right now, as you can see, in the background, our agent is working on this graph-pre-sette layer not addition problem. And it's sort of exploring the solution space and having a visual understanding, it's all right now, a visual understanding of the solutions building. And I can also give a feedback for examples like Alexis an agent here.
And then, so what's what I was going to.
Then, so what's the one?
So the problem we noticed too long as we have. It's just taking a bit too long as we have.
is what happened here.
Okay, so what happened here is that the... This is one node rockling.
and then there is another
Yilan, can you come here?
All right, what is voice tree?
So voice tree.
So Voice is a software that converts
Um, let's actually close all those.
So what is voice tree? That's the question I'm going to answer.
So Voistry is software that converts
your voice into a visual graph.
What that means is as you'll see in a moment as I keep on talking
a note will appear describing what I'm saying on the graph.
Okay.
You're here.
All right. Today I'm working on Voistree. Voistree is a voice to graph software.
which converts your spoken content.
into a visual graph.
So I've been working on the project today and I'm trying to do a live demo.
to some friends.
spoken content to a visual graph.
and today I'm demoing voice tree I'm showing you what it actually looks like so you can get some sort of intuition to it
I'm going to also talk a bit about some of the problems I've been experiencing with Voice Tree and that's related to the
All right, what is voice tree? That's the question about to answer.
and what I'm going to do related to that right now is show you a demo of Voicetree actually working live so you can get some sort of intuition for what Voice Tree actually is.
So,
another thing that I'm doing in parallel to this.
is I want to while demoing Voice Tree, I examine sort of what the problems are with Voice Tree and how I could improve the voice tree system.
So I know already there's a few little quirks that could be improved. So one aspect is improving the graph visualization. One aspect of that is improving the styling of the graph visualization, and another aspect is improving the animation currently when nodes appear.
There's not a pretty animation and sometimes it can just look a bit janky.
Cool.
All right.
So one side is the UI. The UI could be improved we could improve the styling
we can improve the graph visualization and animation. Another aspect to improve is the back end. So we can improve the backend main algorithm.
in the same.
optimization stage. So that I think would be some small changes to the prompt. So let's see, what actually would that involve? So to improve the optimizer back end prompt we could allow it to have a target node name and so when it creates a new node that target node can either be the original node.
It can be a neighbor.
or it can be one of the new nodes itself created.
So that would be pretty cool and I think could improve our
algorithm a lot.
to
Do that.
to realize what node was recently modified.
So
What else can we work on?
So we want to be able to present a demo of voice tree. And we want to be able to do three different types of demo. So we want to be able to do a software engineering demo with use of agents and we want to be able to do a meeting demo with multiple people involved.
And then there's the whole flip side of our project, which is the whole research into using Voistry for improving LLM performance itself.
improving
So we can hover over it
so we can add a terminal to it.
and then with the terminal we can run Claude.
and we can have a look at what the actual file is saying and see if it's generally correct. And then we can give cloud specific instructions. Solve this for the, and then we can give it some files.
and files, what do we actually want? We want to be able to give it.
the chunk processing pipeline.
authentic workflows.
agents.
So that's the name of our agent.
No, we don't want to talk about that.
So let's see what the agent is doing
All right.
Alrighty, today I'm working on.
When do we have to go on?
I'm struggling to make better demo.
What do you think?
Cool. So I just want to show you how the voice tree is growing right now. So I talked about optimizing the optimizer prompt to be able to also target other nodes. And then the LLLM has been working on this in the background. So they made a to-do list, they've started modifying the code to be able to do this to have a target node. name.
and then we get an
an overview of the solution they have done
I think in this case it's implemented more as
of the benefits.
but that's okay.
Cool. So I just want to show you how the voice treat is growing right now. So I have I talked about Optimizing the Optimizer Prompt to be able to also target other nodes and then the LLLM has been working on this in the background so they made to do list they've started modifying the code to be able to do this to have a target node name.
All right today. I'm working on voice tree
its ability to target neighboring nodes and other nodes created in the same iteration. So let's ensure that it can target new nodes edited in the same iteration.
So we'll go to the prompt we'll look at where we're specifying target node
So, we want to be able to do...
So I think here
We need to be able to say define relationships using fill in the blank target no name.
Okay, that is pretty cool. I think that's all we need. We just run a bunchmarker. Let's see how the benchmarker went.
3.8 that's fine
accurate relationships.
Okay, let's have a look at the relationships.
So we want to see what that key relationship it failed is.
So we can open the output view and
So work on voice tree
So it does actually seem...
Yeah I don't think it is
Oh, and maybe our summaries aren't appearing anymore.
Oh, fuck, that's annoying.
Alrighty, today we are working on voice tree.
And our main priority is to make voice tree demoable for the y-collinator demo.
We want to show a few different use cases in that demo.
is the main demo we want to do.
and will demo the benchmark that shows that.
And we make sure we also don't have any bugs in our system. Right now there is a bug in our system.
All right, cool.
system is for a voice tree. We've noticed a few other bugs in the past.
Some voice just gets dropped
which is pretty bad.
and we also want to see our core algorithm how well it's performing.
Okay, a number of thing that I want to do is I also want to remove the parent backlinks in our Markdown. So we can do that by going to our Markdown file.
What is it called?
Treated Markdown and finding the place where we do parent links.
and disable
because it's just add noise so I can write a comment about that.
And now I'm noticing one other bug in our system which is the location.
The location of Wharfenodes when they show up on a graph are in like a really weird
Alrighty today we're working on a voice tree and what I'm realizing is it would be really nice to have a way to load an existing
Markdown tree from our file structure. So whenever we're using voice tree, we end up making quite a big tree.
And it'd be pretty cool to be able to just load an old tree that we had from Markdown files and put that back into our tree data structure. That also shouldn't be too hard.
I don't think that has many contact points.
so there won't be that many errors for it.
Thank you.
Alright so what are what do we specifically need to be able to do voice tree mark downloading okay so the core problem or task is we need to map from mark down representation to our internal tree data structure I think that's called tree underscore d s dot pie or something like that
So to map between them, we need to.
Open all the Markdown files in our Markdown tree bolt or whatever folder we're using just where we will be saving our Mark down files.
I'm
And we need to separate what is a summary and what is a content and what is the title and relationships as well. So we need to recreate the whole tree data structure from the Markdown.
One thing that could make this easier is that when we save our markdown
to a
When we write to mark down initially, we could keep some properties, for example, summary or relationships.
exactly like they show up in the code we should we could save them to the mark down front matter yamel that's very important the front matter yamel can store key value pairs and so that could help make the parsing process not lossless.
I'm
Okay, so we have our task map marked down to tree data structure.
Um
and
we have the idea of potentially retaining properties in the
Yamo front matter.
Um
and we need to overall load the Markdown tree into the tree data structure.
Um,
and
Pars Mark and file components.
Yep, summary, content, title, and relationships are the things we need to post.
So it looks like this task is generally
uh...
comprehensively discussed.
Um.
So I do notice that there's one problem where for some reason we have a duplicate
node now.
Um.
Maybe that's because I repeated everything
Um.
So
Yeah.
We also don't want to get rid of parents when you get rid of children and treat a mark down.
So that we want here we don't want this
Okay.
I'm
Okay, anyway, we can now run an agent on this. So we'll right click terminal.
and
Um.
So let's just pop up this terminal.
Cla dot S.H.
And we are going to say.
work on this task.
you're
Um...
So what does it need it needs?
C tree to markdown dot pie and
And what else is there? Let's also do a commit before.
Don't tell us, okay. And then here save, treat and see, treat a mark on a pie.
and
What else do you want?
C5 find the right entry point for loading.
and
So we're also going to have to change it in our, so in our Claude prompt, we have demo prompt.
If you have coding tasks to solve, the project is in.
do it here.
So I want copy, absolute.
Cool, that should be sufficient.
So now if I close this and I
Run it again.
should just be able to
Okay.
Okay.
That flickering also gets very annoying.
Okay.
Hmm.
No.
730. I'm to start looking at.
Yeah, no, I mean you don't have enough time now to
It's a gem, right?
I'm speaking in English because he's an English model but since I can't actually explain it in German.
But so it's a project called Boy Street. Yeah. And it converts.
No, I can't using an English production model.
I want.
So it converts.
voice to protect and then create a visual graph.
of the, of the, of like this, like so the line map of what you're talking about. So right now I'm talking and just adding content to here. Yeah. It's like signal, saying explanation's being provided in English.
And then if I talk about a related thing, so for example,
The, like it just shouldn't I have to make within this project.
is a decision app to make is how I'm going to demo the best way to demo the project.
then it will also start appearing here. So like right now there's a note here. Yeah. I got me about what I've been saying. And now another one came up demo.
demo strategy decision.
Right, because that's what I was talking about.
That's why we've done.
So if I keep on talking and slowly building the tree. Aha.
And who are we're going to stay?
Boho Brocksters. This is for engineers. Yeah, okay. Then to, for albatim. Yeah.
It's kind of happening.
other days I can organize you.
Yeah, probably and.
problem. So losing. Sulu. Yeah. But out, so the Arbe is another You're here.
Yes, okay, I must have tried it. Yeah. Yeah, okay. So here, when I can't... Yeah.
I can't, if I'm by spiel, I'm gonna, but, uh, work and will. Yeah. But I don't think, yeah, yeah, I can't here a terminal.
And then it's time.
Um,
It can an agent.
running under this.
spout us.
One bomb off the man of the man of kaini mass that we are.
Uh-huh. I don't know how we're doing for me?
five months into part of the day and agents working.
I'm there.
how that's the new thing getting agents would work.
Yeah, so I can show you
Bye.
both.
Well.
Why didn't it make you its fine?
where.
You make me well.
I mean
Okay.
How do you know?
So we haven't.
Yeah.
So I don't think I understand when I speak in German. Okay. But I understood. Maybe you have to speak slowly. Which danden as a...
That's what's up just here. Yeah, it's clear, no, okay? And it's my best, it was...
Yeah
I'm going to say, but I was that I'm not much, but an Andrrhrhrh, and yet is marked as here in Hintergroom. Yeah. So I'm not that's not, but an Underr. Okay, you can't say, I'm not sure, I'll see it, I'm in my Hrissar, I'll just say, then Bautus. Oh, okay. Oh, okay. Yeah.
And I can't think for less than that the other would, so that? Yeah, but I can here see what I'm marked, I can lead in what they're marked, and what is the most problems, and I can...
I can't solve in your name.
But we can't see can't do it in a little bit I had.
Yeah, I can also an impression, for no, these... So I must not here the things, I can't... As a normal way is, I must be here, the reason. Yeah, but my thing is that I can't out here a house, ... Yeah, and I can't... Yeah, but I can't... Yeah, I can't know. you're
That's a bit off the floor. Yeah, that's a good thing.
Yeah, okay. Very good. Hmm. Hmm. So it's that we have things in general, entry, Yeah, yeah, yeah. Yeah, yeah. Yeah, yeah. Yeah, okay.
I didn't.
Thank you.
Oh.
I will probably even describe it. Not very long.
Well, it's not so.
These are the most awesome here.
Thank you.
Thank you.
I am.
and strong with the common best.
on Google. Yeah. You know about, for Inspire or AIDI?
No.
Wow.
Thank you.
Why don't we do a bit of research first, you've done?
I don't know anything about.
Okay.
Hello.
Good thing.
You guys already didn't.
There's a good name in Egypt.
And.
Well, you're not needed.
Good.
So you can go right down below, one below, that, and that.
Oh.
Okay.
Thank you.
I don't think.
I'm just over there.
You do.
type for me.
Well, that's my best friend, yeah. Yeah, one more. One more.
I'm saying I'm saying.
Yeah, we're the whole pocket. What did you mean?
Well, at least it works for that.
What?
Ah.
It will not be able to close.
What?
See the light.
Oh.
All you know.
Thank you.
You have a teleprompter. Yeah, a teleprompter. And then you show the tree, the real world example, you speed it up to the final tree, explain what it's doing, show an agent, zoom in, and then you go show a benchmark, through the benchmark, that's the tree.
This is how it's going to change. It world. And it works. At the end you say this is how it's going to change everything.
Yeah, the impact from from productivity to yeah, yeah, that's the product. Exactly. Call it. And the 7th? CTA. The conclusion is YC. You've found your you.
I see you found your view. And then a picture of you with a user class. I'd be like the idea of saying it. Sounds kind of cool. Yeah, cool. So this is, then you need to see this is how it is going to revolutionize. Okay, for a second.
What are the current revolution now? All age before or? These things we already have. Okay, yeah, but so one month, show the tree, three, the benchmarks, and four, the impacts of the
Yeah.
Yeah. I'm mostly to recognize that this is an improvement and everything that's been out there until now.
Yeah, I think it's big. Yeah, I think rather than you continue to work on it, to just one on that. Having the background video of these things. Yeah.
And you want to want to get all that is better. Yeah, exactly. You're not going to do that in the weekend. No. We have lots of nature. So this is what's being made right then on. So this is what's being made right then on. I think so when you're talking about. I thought that was quite so do we, with the voice, not the actual video.
Uh,
like it's talking about you know what we talked about the demonstration preparation instruction demonstration installation for this benchmarking but I could force it to make new notes for you know that's sort of when you're like it does the video's to be shot live in edit. Yeah, definitely live. Exactly. Because that was the problem with the one you did with with your Google one. It was just too slow, the nodes being created. It was really slow after this. And you have like this 30 second thing of a reading, which I think is really good. I don't think we need to show the actual meeting and transcription of this. But it was just like, it was really slow to build this. you have to really be kind of honest. I think you should concentrate now finding one example of all the things you've already done. Yeah. Or your user meaning of something. I mean, I think it would be best to show how a software engineer which is. Yeah. Because you know something. And then you can see after because it's also going to be applicable for the...
Project One, if it was a product. I don't know how I can engineer myself how it can be useful. But it can also be used in many other. Yeah, that I will only demonstrate one short one here.
My too heavy, I was 8 kilos because all the other ways were gone. They only had to be 16, the age of 16, for my sports and the age in which hand. But my family definitely was. You and I can be rich.
Thank you.
All right, hey, I'm the CEO of Boy Street. Boy Street, West Street.
software that he works text streams into abstraction grounds.
Yeah.
I have a little license.
Okay.
shape.
Yeah.
What time do peace indeed for this prayer?
That's not short.
7. Sorry for 7. We want to hear that of those six, right?
But we're not going to do it, but it's going to smack.
Okay.
Okay, and we have a problem right now that we need to fix, which is, well right now it's actually the positioning of the nodes and the growth.
Okay, and then another thing related to being a CEO of moisture is that I have to why see demo.
I'm Immonon Mason and I'm the founder of Wiestry.
Voice Street is a new way to interact with AI.
Boistery has a core algorithm.
which is.
related to converting.
So the main part we do is converting voice into a tree or a visual mind that was formed.
Hey, why come there. I'm Bonner Mason. I'm a founder of a voice to tree.
voice to tree converts live voice into a knowledge wrap.
Okay. Um, and I went to shoot.
And so one of all I have now is that the voice transcription is not quite high quality because I'm running it on a possible model for it to be more alive. What is what is the...
Hey Y-Cominator, I'm Mahdi Mason.
and I'm the founder of Voice Free.
So what I'm here to show you today? I'm here to show you this software that I've created.
that converts live spoken.
boys into a graph woman.
And.
Thank you.
Why is this useful?
The reason why it isn't useful is that it externalizes your...
short amendment.
Maybe again.
Yeah.
I'm working on a voice tree and the first thing I'm realizing is we still have some problems in our voice to text transcription model.
and that's all have to improve that. And that's potentially due to.
Well, we don't know yet what it's to YouTube. So the first thing we're going to do is going to do to see what the, see if we can understand what the problems are.
I'm not working on that right now. You can help, you can tell that to be a landlord.
Jack it out the green one and 7th are here.
No, ma'am. Thank you.
Thank you.
Thank you.
All righty. Okay, cool. So today we're working on voice tree and we want to so the main thing we're doing is we want to be able to prepare for our Y Combinator live demo.
and
To do that we want essentially some
Good.
to be able to use voice tree live and have it look fairly decent.
the new voice-to-text algorithm for voice tree and seeing how good it is.
All righty, so how good is voice tree? How good is the voice to text? That's some of the questions we have and we want to see...
also things like what is the total time out.
So.
Okay, and now we want to think about ways we could improve the voice to text algorithm for a voice tree and we want to figure out if the
version that just got sent through is actually better. The one that Gemini sent us.
Amazing. So our voice to text algorithm now is actually working really impressively well. Very rapid.
very live it might be good enough to use for the demo because we have a demo for Y Combinator which is a while we're...
to improve this algorithm and so maybe it's good enough now.
Thank you.
Oh, that's all good.
You don't have to put.
Great.
And so now we're noticing more just some problems with the voice transcription.
So let's do voice to text. Let's see what currently condition on previous text.
You don't stop.
Yeah.
W.
And in the form, now to the air. Yeah.
Yes.
Good luck.
So we're asking to come on here. Oh. Yes. Great.
But give it to where.
I'm sorry.
Yeah.
I can.
on Voice.
Alrighty, okay, so today we're working in Voice Train. Voice and software which converts Voice into a
graph format.
All right now we're going to see if we can use the old
turbo model for voice transcription and if that's any better.
VoiceTree. VoiceTree is software which converts voice into a visual graph format.
Alrighty, today we're working on VoiceTree. VoiceTree is software which converts voice into a visual graph format. Nice.
Okay, so now we just want to test the total latency.
Okay, cool. We are just working on improving the voice-to-text algorithm for VoiceTree. And we see...
there's some sort of blocking or something with the main algorithm. So we want to check that.
And so now I want to especially see if we can get text.
If we can get text transcribed while the main algorithm is running.
Au.
and that is a bit hard to figure out. So let's test one, two, three.
Thank you.
Thank you.
Thank you.
Thank you.
Thanks.
Only the second round he knows, so we're waiting.
Thank you.
I don't know.
Alright, cool. So what is VoiceTree?
and what all right cool so what is voice tree and what are we going to work on today
All right, cool. So one thing we wanted to test was when we're creating new nodes, what exactly happens?
So we had a problem before where new nodes would block. So when we're running our main loop, it would block.
And we want to know now, is it still blocking?
Okay, and now it looks like it's not blocking the main loop, which is rather excellent. And now...
Ideally, one thing we still want to do is find out if there is a faster voice text model.
So we currently get to choose between whisper medium and whisper large distill and whisper large.
Turbo and whisper large turbo is the the fastest I'm sorry whisper large turbo is the best
Um, whisper mediums are the fastest, but it's not quite good enough. Um, so we need to decide between those.
I'll plug your G here.
Hey, Y Combinator. I'm Hanu Mason, and I'm the founder of VoiceTree. VoiceTree is software which converts...
extremes into abstraction graphs. So what the hell does that mean? I'll show you an example.
Um, so what exactly I mean by this?
Thanks.
Hey Y Commenter, I'm Manu Mason, and I...
have been working the past year and a half on software that
improves the way that provides a new way of working.
A lot of this has been centered around a core algorithm, which I call...
VoiceTree. VoiceTree takes a text.
and converts it into a visual graph format.
Hey Y Combinator, I'm Manu Mason, and I've been busy building software that unlocks a new system of humanity.
AI collaboration. What does that mean? So this system is centered around our core algorithm called
voice stream which converts text streams for example live voice into a tree format like
a Mindman.
This is our platform and on top of it so much as possible. We have so far focused on two
awesome use cases. The first is an interface for engineers to manage multiple coding agents. The second
is improving agents themselves through compressing and better representing their context with VoiceTree.
Hey Y Combinator, I'm Manu Mason. I've been busy building software that unlocks a new system for human
AI collaboration. What does that mean? Well, to understand that, first...
understand our core algorithm.
called VoiceTree, which converts text streams, such as LiveVoice, into a tree format, like a mind map.
This is our platform. On top of it, so much as possible. We have so far focused on two awesome use cases.
The first...
is an interface for engineers to manage multiple coding agents.
The second is improving agents themselves through compressing and better representing their context with VoiceTree.
So here it's listening and then if I have here
I'll show you.
so i can do it like this oops so you can see that it's recording yeah and if i have here and then it just needs to be
perfect though, the transcript. Oh my god. Okay, let me close this one. And what happened to the idea that happened? So here is the transcript, and then it... Yeah, but it's...
terrible when it tells you loaded environment well I don't need that you can get rid of that okay okay but then it can just show you what is actually happening okay
And then you can see it appear live in the screen and what about the thing with the voice? So here it says like creating new node and then it the new node
appears it helps people understand what's going on yeah cool okay and so here what what
I can fine tune it to create the ideal graph, right? So we have introduction, I'm Monomason, I've been building the building.
software that locks a new system for human eye calibration so this one it got pretty well
And then...
I have voice tree, the core algorithm.
Mm-hmm. And then we have the use cases.
And I don't know if it should be connected to a voice tree.
Or if it should be connected to human eye collaboration so it looks better like this like this. Yeah
Could we then show with the same one the agents start working on that or you would do a different example for that I can
I can show them quickly, so on any node, you can open a terminal.
which
So, right now it's a... I don't like that it always rearranges. Yeah, I've been working on fixing that. So now, so right now I've fixed...
it so that new nodes appear, don't rearrange it, but I just don't even fix it a terminal rearranges it. And then I can show them that you can open a terminal and run.
Minor delusion.
Um...
And so that could be the dummy, you know, and then we show them the, here's what that looks like. And then there's a complex version. And what are you going to use for that?
for the practice one, the real one.
um what do you mean what what what voice tree are you going to use for when you're showing the real complex well i'll try and make one you'll try and make one yeah
I think that's very good. Once you have some footage, you send to me. I keep doing a bit of research on the Canva. So what else should I say?
does this make sense yeah like because it sort of is like wow okay human AI collaboration well
What is that? Then they see the graph being made, and they say, oh, okay. And then...
The first interface should I say the second which we didn't like should I tell them that we didn't realize it? I wouldn't say it
We can say it in like the interview or in the documentation, but I wouldn't say in the video. Yeah, but should I say like
say about why it's useful for humans and AIs, a bit about like that, like the memory optimization. Yeah, exactly.
Where would I put that here? No a bit later when you started describing what the second is. Why?
How are these two use cases connected? Disconnected.
Why does it actually help? Let me get my, I have, I've been starting to work on a script.
Hey Y Combinator, I'm Manu Mason. I've been busy building software that unlocks a new system for human AI collaboration.

This system is centered around our core algorithm called VoiceTree, which converts text streams
such as live voice.
into a tree representation, similar to a mind map.

Hey Y Combinator, I'm Manu Mason and I've been busy building software that unlocks a new system for human AI collaboration.
This system is centered around our core algorithm called VoiceTree, which converts text streams, such as a live voice, into a tree representation.
presentation, similar to a mind map.
It's running right now live.
What's the benefit of this? The tree allows for a more efficient representation of content, decreasing cognitive load by...
providing a memory aid for the high-level concepts and the relationships between them rather than get lost in the detail.
As we'll see soon, both humans and LLMs can benefit from this.
On top of this VoiceTree platform, so much is possible. We have so far focused on two awesome use cases.
The first is an interface for software engineers to manage multiple coding agents.
The second is improving agents themselves through compressing and better representing their context with Voice Street.
All righty. Hey, I'm working on VoiceTree today and I'm trying to get ready for the demo, which is due Monday. And today was meant to be spending working on recording some examples of using VoiceTree.
Okay, cool. So, let's see. This one we can close. All right, so, voice-through demo preparation, what do we need to do? So, one thing we need to do is we wanted just a leftover task from yesterday was to improve the Zoom.
So I'm going to improve the zoom behavior when we open a terminal.
Okay, improved zoom behavior. Another thing we wanted to do on the UI side was to add the animation that shows a breathing effect for new nodes.
Um, we're also doing sort of a meta thing right now, which is we want to get sort of an idea of the behavior right now of VoiceTree, um, so that we can, um, get some good intuition for how we could improve it in the future. Okay, let's talk a bit about add breathing animation for new nodes. What do we need to do there exactly? Um, so I think we already have the breathing animation. Um, yeah.
on on when you um pin a node um so we can see that's working right now um and so all i think we need to do is um add the animation um for when just actually a new node is added um and i think we can do that um how can we do that we can do that i think on the ui side uh detecting when a node is either added or modified
And perhaps we can have a slightly different animation for new nodes versus nodes that got appended to.
Um...
Cool. And I remember we had some example of that from before. So let me try to find that. It was here. Okay, let's just close these. So I think we had, if I do Claude, I think I can find an example. Might be this one. Yeah.
We can either, so we have a choice now, we can either do it on the, completely on the front end side by adding this class when we detect a new node, or we can do it partly on the back end side by adding the class to new nodes versus just. So it might work, right, if we just, on the back end side.
of VoiceTree, when we create a new node, create it with a class, and that class has an animation that stops after 15 seconds or so. And we can do the same when we append to a node. We can, in the back end, add a class recently appended. But then what are we going to do? We can't really remove the class. We want to see right now what the current process is for removing a class. So I think that would...
Because in our commit history, we can find how we're currently removing the animation when hover is triggered. We have stop breathing animation for node, in previous method stop breathing animation for node, and where is that defined?
Okay, I'm realizing is now as well is that these workspace mode TS files are huge and we should try to extract the logic for the breathing animation.
Hmm.
So now I want to figure out which approach we should go with, the back-end or front-end approach for breathing.
And I don't really know yet, so we're going to have to split that into two nodes so we can make a decision there about it, backend versus frontend.
Okay, I think now's a good time to get an agent to help with this. So let's open up an agent. Let me just check what cloud we have on that.
I think we want to use a different demo prompt for Cloud.
so we have new demo prompt we're just setting up um the ability to use agent from voice true really quickly
Okay, so we should now have everything we need. Let's test it out now. So if I run cloud from here, and I just want to get our repository.
So let's copy
So wait, replay is in the news first.
Now that is running.
Let's also work on the extraction. Okay, what can you do? Just change the setting here.
Zoom on active nodes, don't need them. Here we're going to run cloud again.
Okay, what are you doing?
Okay, so we got write thousand in.
Okay, excellent. So our agent's gonna work on the extraction there. We do need to kind of figure out how to
Yeah, it needs to be like the relative.
hmm yeah i don't know quite how to do that so we could get clod to run in our root in just repos that could be the best option to stop all these errors um okay so yeah voice tree that's one problem we have right now where terminals um when they open agents when agents open on the tree um they don't they open in the directory of our voice tree um when they should probably open in the repo root um
So they have access to all our different repos. Otherwise, they keep on having to do like relative path hacks. So that's one thing we can improve later. Okay, let's see what this guy is saying.
Let's see.
I don't know if the agent execution context in repository root is really a priority for now. I think let's just focus on getting the breathing working.
And we can check the diff.
that's going to be unversioned. Okay, let's go into
Okay. I'm reviewing the breathing animation it wrote right now. Looks okay. I think we're just going to need to test it.
Thank you.
Okay, I think we should actually fix the agent execution context repository root because otherwise everything just takes twice as long. So let's get, I think we can just do this manually. So let's go into our clod. And then we want to do, we want to cd into finder repos.
Man this is so so cool
Is that the, let's just try this. Okay, those are all our repos. And then let's put the demo prompt that we want into there. And then we also have a few, we have agent workflow. These are our,
Okay, cool.
Okay, and now I'm just noticing, so we've done the running, we now run Claude from the repo route, and I'm also noticing just while I'm running VoiceTree Live, I'm noticing we're getting a few errors in our abstraction stage. Alarm returned invalid JSON.
And that happens really often. And so we'd ideally want a better way of addressing the JSON, parsing the JSON. Let's copy all that and try run an agent on it. And so let's go into our, where's our JSON? Yep.
We can add the actual error here and then please first look at the debug logs for the optimizer.
all right all right okay let's get our terminals back um and then let's run a terminal adjacent
Okay, so...
Why didn't that work? Oh, right, it's in the root now. Okay, so now we should be able to call it. Oh, and now we need...
to give the full link to the file that it got opened from so that should be let's think
ObsidianVaultPath is what we want there
Oh fuck, I'm just going to go put it in.
Okay, cool. Let's try it again now. Okay, so now that's guys.
gonna run on our invalid errors let's see what happened to this guy okay so you say he's updated he's done it let's see and it's not bad
um
Okay, let's see if this works now so we can, okay, I'll just run it for, I'm still using the old.
Okay, now we need to update and go reload juggle.
Okay, now we want to test if the breathing animation works if we add a new node. Let me reload juggle one more time. So we're now testing the animation for if it works. And it should be right now.
Wow, it's pretty cool. That worked, actually. The appended content. Now, what is it doing? Under parent five. So it looked like, perhaps, where's test breathing? I don't see the test breathing.
updating node 5 creating child node tests breathing animation functionality where is that i don't see it
Oh, all right, so it doesn't seem to be working for new nodes, but it does seem to be working for appending a node. All right, let's just move on for a second and check how our other agents did. So unfortunately, when we reloaded juggle, we lost our terminals, but that is fine.
Let's see what this guy did
Okay, this guy got really confused.
I think it might be because when we pasted the content, it got a bit fucked up. Oh, we have a problem right now where we overwrite. Yeah, okay, that's why. So I think what happened here is if I hover over it, yeah, the JSON got removed. So when we go to update, we need to actually send through the real content. For the update, that is another big problem with voice trees that currently we just store it internally.
within the tree um but we actually need to store it to store it uh to read from markdown to see if anything's been modified um that's just really important we need that
Okay, and then let's tell this guy, okay.
Okay, so while that's running, let's check the...
Okay, so they're thinking they might need to add a small delay to the new node to ensure that the animation actually gets created. There's probably like a bit of rest condition there. Okay, let's see.
so we should be on version 129 they've built it let's reload okay um and now let's talk about a completely unrelated topic which is i want to go to the gym today um or go on a run and i want to figure out if i should go in a gym or go on a run um and i don't know what to do what what should i do um a bit of a backlog here but hopefully we should in a second be able to see a new node being created
Let me just create some of your song. So, did that work? Where is our... No, it still didn't work. So, I'm looking...
at gym versus run right now and i've decided i'm gonna go on a run because my priority is cardio would be nice to sort of be able to also search for node that could be cool as well
But the breathing effect should be sufficient here, if it works. Okay, so there, appended content's working. Wait a second, that seemed to be the same as the still-timed-out. Maybe we're running on the old versions of the older console. Let's see. So it's...
See what version of juggle we're on. 127. And what was this guy saying we should be on? 129. So he didn't actually build it. Weird. Let's build it one more time. Sometimes strange things happen, that's okay. Okay, let's open up a new...
Okay, let's open up. There we go. All right, so we want to test two things. We want to test one, appending to a node. And we want to test two, creating a completely new node. Let's talk about, one thing I want to talk about is working with Elan today. I want to figure out what the best thing to do with Elan is. I'm not quite sure what that is going to be, but we'll figure it out together. Hopefully we'll get some overlap.
time. I hope he's not driving off to Brussels today. Okay, nice. We got an append and a create. Let's see. Nice. Our append is working. That's awesome. And then new nodes still aren't getting the animation, which is very annoying. But that is really cool.
Stops when I hover over. Awesome. Now let's just fix. So let's go terminal here. Thanks for the hover animation. We go Claude and then let's do breathing animation is working.
New nerds.
I wonder what happens if I hide a node since it's done. It'd be nice if hide would remove all the dependents as well. We could work on that later at some point. This one was done as well. Is there a collapse selection? Okay, that worked pretty well. Oh, wow, it worked. Ah, you can collapse the selection.
I'll add new node. We need to add new node.
Let's try to fix the internal storage now.
Okay.
Thank you.
Let's see how this guy did. Okay, now let's deploy one more time. Build, building, it'd be 131.
Now I want to add a new node about what food I might eat today. So that should be a completely new node, what food I should eat today. I think I might need to open a new graph, unfortunately. It's also... So...
Okay, let's see if that worked. Completely new node. Fuck, man. Let's try like a five second delay.
Okay, this is getting pretty messy. Let's just, I think we might need to open up a new version of Obsidian.
Okay, we want another completely new node about buying some dental floss today.
Okay, new node, dental floss, it still didn't work, what the hell?
I'm going to turn this down.
Okay, we have the logic here, the new node is in the wrong place. It should be, you can see, the bugs for the new node that we expect.
Good idea.
it was because i was i've took my earpods out and so the microphone stopped working um but it still might not work it's okay
All right, it looks like finally we're working. So let's make a new node at breathing animation failure on new nodes. And let's call it, we have fixed the solution.
Nice, so it got appended, and then that's going to result in soon some new nodes being spawned. So you can see the content right now as this newly appended content, which hasn't been resulted in new nodes yet. And now there's a new node, and it's doing the green animation. That is pretty awesome. So we're done.
Hey Y Combinator, I'm Manu Mason. I've been busy building software that unlocks a new system for human AI collaboration. This system is centered around our core algorithm called VoiceTree, which converts text streams such as live voice into a tree representation similar to a mind map. It's running right now live.
What's the benefit of this? The tree allows for a more efficient representation of content, decreasing cognitive load by providing a memory aid for the high-level concepts and relationships between them, rather than getting lost in the detail. As we'll see soon, both humans and LLMs can benefit from this.
On top of this VoiceTree platform, so much is possible, we have so far focused on two awesome use cases.
The first is an interface for software engineers to manage multiple coding agents.
The second is improving agents themselves through compressing and better representing the context with VoiceTree.
Amen.
Pick this, eat in the car, I have grapes, I have grapes, covenal tree, I'll wash them and put them in a little bag. Sad money's not coming. Well, I'm ready to put it here.
I won't even jump on and say goodbye. Yeah, of course. I'm not going to leave for another hour. I want to work with mine for an hour. Oh, good, good. Here. Here's this with the others. Thanks, thanks. And that, brother.
My children, but they were nine-year-olds. For kilos? No! For a little... They just sit on the fridge. They don't need to do anything for each other. Can I find another one? That is a little yellow stuff. I don't know what they yellow mean. I said, take me home. Just press X. You're sending feedback. You're sending a screenshot. You're sending...
yeah to find yourself you press no that one yeah that takes you to where you are okay that's the blue yeah and then you look for directions yeah well that button where you search for it let's see I switch you again
another deal company. I got completely turned around though.
Now we're going to show you the run agent functionality.
I did 90,000 steps. That's good. That's good. And then I bought all that food. Thank you. We can have... And apologize. Just apologize for telling me first. Lance said you annoyed him, so he's leaving. Yeah, that's right. And then she changed it. Well, we both annoyed him. But she said, he said, you. I don't like that. Even if it's true, she said... I'm fair. Oh, Linda. Thank you.
She said it, she just said something. Linda, she sent me something. Hamas' fundamental plan for survival is Gaza's humanitarian suffering. Dad, just block her. Real junk. I mean, there's good stuff in every major newspaper, every major international human rights foundation, everything. And she sends me something.
piece of junk by some guy who's by himself writing something pro-Israel. She doesn't see it. Nothing you can do about it. What is the ideal time for doing a plank? Ilan, when are you available? You don't have to work on this. You don't want to. I want to work on it, Manu. Yeah. But what do you want me to do? I can't just sit and watch you cold. I mean, but Ilan, come on. But that's not working. We know that's not working. Yeah, what do you want me to do? Well, you just, you, let's work for an hour on it. Okay, what do we do?
Well, are you ready to work for now on it? Do you need to do anything else? Let me have a shower. I feel horrible Manu I can't really use my brain when I feel like that I'm sorry Alon
Headache, maybe I'll go with you to Brussels. Yeah, I can take a trip back
and go to the gym there.
All right, how are these two use cases connected for VoiceTree and why does it actually help?
over 60 do a plank for 20 seconds i do two minutes but they say it's much harder the way i do it on my elbows they say you should do it like this it's much easier is that true
Yeah, it is much easier like that. I'll do both. You guys should go to the gym later. Yeah. I'm going to do a workout now in case we...
It could go with you with that. No, don't worry.
have you seen a yoga mat no i haven't sorry i have not seen the yoga mats
is that the right form for a plank not to push up no but they said to do the plank this way and then to make it harder you go on your elbow okay don't but you can but you usually do it on your elbows yeah that's the harder way they say well but you want the harder way yeah i first do this for half a minute and then i do another minute the other way okay yeah this way
They said after 60 you should be able to do 20 seconds.
I like it when our trainer puts a heavy weight on me.
Okay, one thing I want to do for VoiceTree is have each agent, when they run, be given their own unique color to add to the graph with. And I think we can change the add new node.
Python function to do that
So
Okay.
And then let's go here. Let's edit it.
So we can
C add new node.py
and
okay so I've added some content to assign unique agent colors and I want you to have a look at that and see if you can see the content
Alrighty, so I'm going to get Ilan to work with me for an hour and I'm going to show him what I currently have and get his feedback on what to prioritize and questions like that. So let's first just reload everything. Hello, this is Ilan.
Okay, Elan, so we have collaboration with Elan for feedback and prioritization. Very good. I've seen the most recent demonstrations and I think you've moved in a very good direction. Yeah, yeah, that's good. So yeah, let's figure out what we actually need to properly truly work on. So let's first just, I'm just going to show you a demo of VoiceTree and the current state of VoiceTree. I think you'll notice that the main problem right now is that it's just a bit too slow, but that's fine for the demo. It's fine for the demo because you'll just speed it up. Yeah. Yeah.
It's just for some reason, I think, so once you stop talking.
It starts processing the audio either go and so See there got like a really long set of text to transcribe hmm, so I need to have maybe sort of like a way to Encourage it to flush early, but anyway And so now look you can see this Elon is that this one got appended to and this one's a new node which is slowness and so if I look at what it says The main problem with voice use currently the two Sloan is you address the future development sweet. This is very accurate It does need to be just a future development, but I don't think that that's a priority for Monday right for Monday I think this is the priority and the demo video. Okay, cool So what we want to prioritize is the Y combinator demo
And for the Y Combinator demo, we have two artifacts that we need to publish. One is the written application, and the other is the demo video. On the written application, I've completed your founder profile, but I think you need to...
Go through it. Obviously, I think you need to think about the Equity if you have an incorporate you expect to have it's unlikely to be a hundred percent. I don't get really how that works I filled out all this stuff. Yeah, thank God I think what you need to look at is the text here because I just took it from you Yeah, I think I should also just remove some of those right like it's it's really just Elastin, Melbourne, Optiver That matters. Yeah No, I think they're all good. I would put them all in mmm Shows that you were ready ten years ago already. A yeah, a founder I copied and pasted this from your LinkedIn. Yeah you need to Think about whether this is the thing you want. Yeah, just from your LinkedIn here to put in your HSE scores and I don't
I think you had the Dean's Honours list, right? No, I didn't. But hey, I added some stuff here. Did it not say? No, it didn't say.
Let me see if it's in my one.
So I had some things to the application you had your old application remember no no it was in this one because you had text From your old application. I put it in the ice was looking at the one you wrote. Yeah
And let's see, profo.
Okay, anyway, I'll edit that. Yeah, that's fine. Then in the actual company and the only ones that I found possible for me to do
Were these which I just did with AI. I'm not saying they're very impressed But I spoke a lot with AI to get it and I think it's really good But I think you should you need to look at this as well because one of them is competitors And that's purely from AI. I didn't spend much time on that one. Okay, let me look at let me look at this
Okay, so we have, hang on, I can't, oh here.
Okay, sweet, yeah. This is what AI said was competitors of yours, but you really need to double change that.
Yeah. Okay, cool.
Is it really B2B SaaS? Yeah, yeah, of course. I think they have like AI or something probably at this point, right? No, okay, anyway. Other ideas I can add? I would put in something more about the meeting transcription and stuff like that there. Yeah. But I mean, that's the same idea. I'm not playing with a different idea. I have two, I've got, I'm working on two other startups though, so I can mention them there. I just want to see that you're, you know, you have lots of ideas and you're curious. Okay, cool. So yeah, written application for Y Combinator Demo, AI-generated competitor analysis. So the written stuff for the Y Combinator Demo really requires your work now, but I'm happy to go through it and edit it and work on the language and...
brainstorm it with you but I don't think I can write it I mean if you give me the content I can write it but okay and then so we can look I can look at this review it and then give you add some bullet points for you to merge back in that could be good mm-hmm and I'm good at writing I will write it myself not with AI okay if you bring me bullet points okay so that's that that's gonna be those two nodes that are about to pop up but let's think for a minute now about the the video demo because for the video demo
So, video demo, we want, so essentially I want to know right now, is it sufficient? So, we would do something like this, where we have the demo script, right, which creates those three nodes explaining what voice tree is. And then I can show them the functionality of, so here's what I call a demo video, that is pretty cool, and then I can do the terminal, and then I can open a terminal, and run Claude, and I can just say just create some mock.
file to when you say make a script for the well so I want to just so what I'm thinking is so for like as an if we have the full flow of our demo we start with our demo just explaining what voice tree is with the graph appearing and then and then I show the agent functionality and on top of the the one we've been using voice for just to explain there's not much I can actually do but then all that is is to quickly show that you can run agents and do anything but I don't know what the prompt should be because I can get to do anything but I mean here look what it's doing
that's just creating some dummy files. See?
Like that? Mm-hmm.
Right. But don't tell it when you do the demo to make dummy files. Yeah. It's like a bit more complex. Make a business plan or something. Yeah. And I can still speed it up if necessary. And then I'm going to go into my example of actually using VoiceTree for development. And it's real. It's going to be me actually developing something. Have you already shot that? Well, I keep on recording lots. But the problem is that they're not exactly... I think, you know, every time it gets better and better. So I think by the time I'll be able to make a really good one. One thing is I want the same agent to all be the same color. That I've been trying to fix. But it should be easy. So cool. So we have... Our full flow is we have...
the so we have the demo video Right and the demo video starts with me explaining voice tree using voice tree And then I show agent functionality and then I move to using voice tree for for real live demo and then we start saying the breakthrough we realized was that if the agents themselves use voice treated it to represent their internal memory They become more efficient and accurate and then we talk a little bit like whiteboard style explaining what it is Because it's complicated and then we show some benchmarks. Yeah, or and maybe we show one example one real-life use case of how that could work
Absolutely, I think that's still something we should do. Yeah, how could we do that? Okay, so hold that thought of how we could use the How we could do that last part of the demo. I just want to first know is the first part of the demo Good genug, so is everything there? It's pretty cool, right?
Is it can I tell you what I imagined? Yeah While you're speaking. This was the script that so this is what you're imagining. Yeah My name is on a voice tree blah blah blah blah blah and then it would come up No one speak type or add documents. No two dynamic. I must move those. No three ages automate work So it's actually coming up with the features like on the mock website. I made for you that you didn't like so much Right, but that's what's different with that that's your introduction. That's what your ideas So It's this right I showed you that Saying this in the notes. Yeah, exactly and then I'm imagining that the notes pop up We have to voice blah blah blah just like this like this. Yeah Yeah
That's what we're doing. Good. Okay. Then I thought that Perplexity's idea here, that after you do the intro, then you say the problem, which is about the context below it. Yeah. Straight into features. So I think it needs a little bit more. Wait, you kind of do it. So what I was thinking as a possibility was, I was going to do this actually, reminders. So I was going to start with the first intro. It's actually just a slide, maybe. We're showing the impact. Start with the impact, right?
So we have created something that, one, solves key pay points when working with parallel agents. Which are that you don't know what they're doing. It's hard to have an overview. It's not a nice UI. Exactly. All those things. Too complex to manage multiple agents. Improves your problem-solving decision-making ability. Does the same for LLMs while increasing input tokens by 69%. All the same core technology, VoiceDream. And then I go in, hey, I'm Anna Mason. I've been busy building software that unlocks the new system for human integration. Do you think that's a good flow? So this is without VoiceDream. But it's just impact, leader of the impact. I would put that after your entry. So you think, don't...
Don't leave with the impact. They're going to watch the whole video anyway. They're going to watch the whole video anyway. I would start with Hey Why I Comedate, I'm not amazed and I've been building software and then... Yeah, yeah. Okay. And then have... But I think you should also say... Yeah, exactly. You should say what the problem is. So have that here. So when I start talking about interface for software engineers and optimal caging items, so I do now here show them spawning an agent. And then two agents. Two agents makes more sense. Because it shows like... Solves key pay points when working with...
Parallel Coding Agents, I think I actually have that on the website now. I added some stuff to the website last night. Nice, that looks good. So I have here first breakthrough.
Yeah, this idea of them being localized in space. I think it's really neat. Mm-hmm So much easier for your brain to keep track of And then this other thing is really useful all the contacts from what you've been saying out loud becomes the prompts to run your agents on That's so much lower friction than having tied out a prompt with all your contacts from scratch. Yeah. Yeah So that's two benefits, but there's And then it's and then it's the visibility as well. Mm-hmm. So Let's just write down some notes. So show a run agent functionality. That's So the key pay points are Localization in space space reduces
context switching I guess like aligns better with brain we can figure out a really good way to explain it and then don't need to rewrite prompts all the context is in the voice for you ready and then what's that third thing I said visual visual understanding of progress like visibility into the progress into agent progress through their tree updates
Okay, and then improves your problem-solving decision. I mean, see, now we need to think, right? Because, so this part made sense. This part made sense. The graph appears. We show them spawning two agents. And then we can talk a bit about why it improves. Like, see, this is getting into a bit of a, as soon as you start adding why, it's one of the most important thing here. Yeah, you should do something about the scientific basis. Which is, I think, externalizing your short-term memory.
decreasing cognitive load I think that's similar
I think I set it here.
Voice you allow you to decrease in cognitive load there really long you'd say in the flow state longer and solve harder problems But we want to keep that as concise as possible externalizing short-term memory decreasing cognitive load Because for example, it would be pretty hard to remember everything we've talked about right? Yeah, but here's had a meeting Transcript it wouldn't you know? Yeah? Yeah, exactly. You wouldn't be able to read it quickly, but you can get an overview
of, so here we're talking about the Wicommer demo video content flow, which we've been talking about for a while. And then here's the written application that we talked about for a while. So that's a demo video. So I guess this is a collaboration with Elan, Voice Tree Slowness is another thing that we're not prioritizing. So it's pretty cool, right? It's pretty cool. For a meeting, it's pretty cool. Yeah. I need to make these disappear after a while, I think I was. It's just... Anyway. Don't do any of that now. No, no, you're right, you're right, you're right, you're right. It's true. You're really focused on the video. Okay, so...
So first I show it working. I show spawning two agents. I can make one Gemini, one Claude to show agent agnostic. I don't even mention it, right? I can just implicitly, here's a Gemini agent, here's a Claude agent. That's pretty cool in itself. You can have two different types of items in the same thing. Do they talk to each other? Yeah, they can talk to each other as well, through the tree, communication through tree. I vomited mom. You keep saying that. No, because you upset me for me for saying that you were upset with me. What do you think? Did you eat something better?
That's what was wrong. Do you think it's the Manjara? Yeah, I think it's the Manjara. So then I say, externalizing your memory, decreasing cognitive load. And very similar to that is reducing context load. You don't get everything at once, you get an overview. Better conceptual representation. Whatever I end up saying, that makes sense, right? Does that make sense? Better conceptual representations? Like as in, instead of getting a wall of text... There are too many buzzwords. Yeah, how could I make that really... Externalizing short-term memory is already a buzzword. Yeah.
Yeah, maybe I can just use plain English here. Yeah, I use plain English. You don't need to remember the tracing of your thoughts. What? Linking of your thoughts. You don't need to remember the... Like, the idea is, right, like, with deep engineering, you could just go down, like, a path like this, deeper and deeper and deeper. And at every point, you don't need to remember why you're doing it. It's on the tree while you're doing it. And so then you don't need to hold this stack in memory. You don't need to hold the...
um stack trace in memory i think you don't have to take too much anyway we'll figure out a way maybe you can think about the best way to explain that really easily does that make sense or not having to hold the stack trace in memory like if we're working on something and we keep on going down because i don't know how engineers were okay anyway um and does reducing context bloat makes sense like getting a high level overview first yeah i would say that instead before diving before jumping into the details you want more plain english is good yeah i think we're using cognitive yeah
And then the breakthrough, the breakthrough is that this does the same for our lives. And then now I can show... That you need to explain a bit. Yeah. Now I can show... So I can... We will explain shortly, maybe. Well, it depends. We just want to first figure out the best flow for this. Now I can show real demo. And then so we have real live demo. What are you going to have on the screen while you're saying all this? Because this is like... This is like three minutes of text. Yeah, that's a problem. You can only do three minutes in total. So... Let me make this...
into an obsidian open vault. All right so we have YC demo.
Let me just make a new note, YC demo script. So start with that. So this is an intro with BT Live. Okay, and then.
While you're saying all this, VoiceTree will continue building a VoiceTree, right? Yeah. Spawning agents. And now, what problems is this solving? And we don't know exactly where the best place to have it is. And then we want our live, realistic demo. That's way too long. Of me engineering. What are you going to build there? VoiceTree? Yeah, something to do with VoiceTree. I need to go pee. And then we need to do explaining the LLM.
breakthrough. Yeah. Okay. Okay. Have a look at that. See if you can improve the flow of that.
Oh, my body hurts. I guess all that exercise in one day and not doing exercise regularly. I mean, this is also where I want to go home. Use my gym more regularly. You also need to eat more protein. Yeah, I haven't eaten anything.
You're not going to be able to show this part as well. This is going to be three minutes already. You're ready at 360 words. I think you just have to end it there.
Dad you're gonna hurt yourself
not good form no no looks awful you gotta extend your arms you can really hurt yourself with that you can do it just do it i do it when i know well i think ilana live realistic demo is awesome right but we can speed it up we can speed it up and then slow it down just for key moments everything you've said to hear is absolutely important to include but it's a bit duplicated a tiny bit right yeah this part is a bit duplicated what problems is it solving yeah
You kind of already say this here Yeah, yeah, we only need one. I think you don't need this part Manu. Yeah, and you just add some of the parts from here this part To here, which you already have there. Yeah, yeah Okay, I would I would get rid of this cut that out cut out integrate into above. Yeah, show don't tell, right? Exactly Okay, so now we have I would leave tomorrow, but I
to be in brussels by three which means i'd have to leave at six in the morning which is no fun i'd rather drive in the afternoon
I don't get why this one becomes a title, but then it contains everything here. Weird, right? Whoa, careful, Dad.
Dad.
Uh, that's fine. Okay, Ilan.
So live realistic breakthrough, a live realistic demo. And so now, so we want to speed up the boring parts, like of the agents working. Can we think a little bit about what you're going to do there? This is what I want to do now, yeah. Agents working, slow down for key moments. And what are those key moments are? So I have a cool system right now. What feature will you build?
Well, I was thinking I'm just gonna run out on every single next item of work that I'm doing for voice in the next three days Everything we're gonna record and then I'll pick the best one. Yeah, so Ideally something visual though. Mm-hmm like I'm like colors. I was thinking one yet colors is good one thing that could be Good is like so right now when you open is it still recording us. It is still recording us. Yeah When you open a terminal, but this is the sizing is wrong and then only zoom it doesn't like it's not perfect But I mean that's a bit janky too. It's a big voice tree, Manu Considering well, I guess we're talking about a lot of things Well, one thing I wonder in the future is that this collapses into one this collapses into one
This collapses into one. Okay, right, and then it only expands the current thing you're working on cool Yeah, it's good. Yeah, I think it's already something big to figure out where something is. Yeah, yeah
Yeah, no, I agree. That's the feature I need, but it's just not the priority right now. Okay, so slow down for key moments.
So, okay, so we want something visual, perhaps a dummy example if necessary. Like a made-up. Something you know you can do. If necessary. Speed up the boring parts of the agent's working, slow down for key moments. Spawning agents, modifying the note content manually.
agents creating nodes themselves and so I have this cool system as well where what I've done is so here I don't have it set up right now but what you can do is so normally I just
So normally it's just Claude, right? But I have one which is like Claude Claude with sub agents and what that guy does is whatever task you give it
It splits it into subtasks, creates a note for every subtask, and then creates an agent file, like they call them like Bob or Melissa. I've seen it. And then on each of those subtasks, I can run the subagent and have this main agent as the controller. And that's a pretty cool workflow, but it's confusing. It's confusing. It's very confusing, and it takes a while to explain. You can't explain it in three minutes. So I think maybe better to avoid it. Thank you.
And I can, you know, in the meantime, publish that online. People will love it. So the other really cool thing, right, is that this is cool. So, so, let me just go voice. We started something called VoiceTree. India. Yeah, but they renamed it, and it's now VoiceTree is trademarked. Okay. You have to change the name slightly. Do you want to see where it's trademarked? Yeah, they said it's trademarked. Okay, so, um.
So, so VoiceTree UI, I can, okay dad wait, can you just give me a excuse for five minutes? He's trying to help. Thank you dad. I know, he knows. So, VoiceTree UI is public, the UI for this, but the actual algorithm, this one's private. So, and that's cool, right? We can say that we're closed core, open core and closed core open, whatever it was called. Something like, yeah, I remember the words. So, the UI can be public and the UI still allows people to run the agents and things, but they don't get the benefit of having the VoiceTree. And so then that might make them like try it out and think, cool, it'd be really cool now to have the VoiceTree component of this.
Anyway, okay, so what's yeah, what's priority? What's what's missing?
priority is definitely the live realistic demo we should definitely make some things yeah and that's it I think Manu I think it's pretty good I mean three minutes is short and then another priority is the one minute founder demo and that's where you talk about that's where they talk about all the things that aren't in here like your experience at Atlassian the fact that you were already yeah and years ago you're focused on infrastructure and optimization yeah this one personal life you love focusing on your fitness things like this I'm a software
I think I like this one the most as well.
Mm-hmm.
Let's go down.
Yeah, it's pretty cool, Manu. I think it's a good script.
Yeah. I noticed that some of the script videos tickle a bit more about what their company is.
But you have that in the demo. But that's the demo. I think this should be talking about you. Yeah. No, no, no, I think this is good. And why I'm the person to work on this. Yeah, exactly. And I think you should add something about how kind of optimization and performance is something you're really passionate about, including in your own life.
Yeah
So I could do that here Optimization and performance is something I am truly passionate passionate about about in all areas of my life Optimizing my health my health my productivity My fitness my software My health my fitness my productivity my software does it sound a bit asshole to me? No, it sounds very very sounds like you're the right type of guy to work. Yes. Yeah, you are I mean you really genuinely are this is
This is really your project. Yeah.
We could link this really well. We have something about who I am. The evidence for that. Last year I made tons of money for Atlassian. And now... You really saved them 8 million a year? Something like that. I'll look up the exact amount. So last year...
Now, applying that same mindset towards a new system for human and eye interactions. Very good.
Yeah, I would get rid of the other ones. Yeah. They're all part of it, but the main thing is the new system.
Take out that one.
Towards a new system. Okay, and now let's just quickly delete the things that I don't need. What about artificial brokers? Simulating market dynamics for realistic load testing. I'm just thinking, I only have a minute. I shouldn't be talking about what I did at... I wouldn't even mention Optiverts in your CV. Is there any relevance of it to... No, but it's like, people in tech think it's really cool. Wasn't it an internship? Yeah, it was just an internship. People in tech think it's really cool if you worked at HFT companies. Yeah?
Yeah, sure. So let's hear you say it out loud. Hey YC, I'm Manu Mason. I'm a software performance engineer at Atlassian, where my team focuses on optimizing Jira for our largest customers. Previously, I was at Optiver, a high frequency trading company. I studied discrete maths and operations research and computer science at the University of Melbourne. Optimization performance is something I'm truly passionate about in all areas of my life. Optimizing my health, my fitness, my productivity, and my software. Last year, I led eight different optimization products in the Jira system and saved 8 million in AWS costs. Now, in this past year, I've been applying my performance optimization mindset and skills towards a new system for human AI interactions. Recently,
I've made some fascinating breakthroughs and progress and I'm really excited to show you what we've been working on. Let's launch a company together. Cool. Maybe let's launch a company together is not good because it implies that I don't have a company yet. Maybe you don't. Yeah.
Is that good? Yeah, I think it's great. They say in all their stuff that it's very okay if you don't have a company yet. But I think you do need to work a little bit on the company structure. And that's something I can maybe help you a little bit more on than other things. Okay, and now we have the YC demo script flow. Hey, Y Combinator, I'm Mono Mason. I've been busy building software that unlocks a new system for human AI collaboration. This system is centered around a core algorithm called VoiceTree, which converts text streams into tree representations. It reminds me of that. I should maybe have, I think, one sentence here about what that is. Yeah. Right? Because it's just, I've always buzzwords. One really concrete sentence. Yeah, way to manage agents, manage productivity. This is all based around a plot.
Okay, that sucks, but anyway, I'm just thinking, what did you say? Towards a new system for human AI interactions. I'm calling it VoiceTree. It is. Yeah. I've called it. I'm calling it VoiceTree. VoiceTree.
And...
Maybe I can say it's centered around this platform I call VoiceTree I built called VoiceTree
Which?
Convert your ideas into mind maps. Yeah, which converts which turns your ideas. I would say which creates mind maps turns your ideas, but I could do really really explicitly which Converts no text. No because it's not a it's not a demo It's not the tech thing you've told them that already four times in the application in the demo video. Right. Yeah, okay Yeah, really high level
And could I relate it to optimization and performance?
How? Weed.
Alright, let's do what you would say. What would you exactly say? A new system for human AI interactions. I'm calling it VoiceTree. And it's a platform to turn your ideas into mind maps, manage agents and improve LLM capability or something like that.
Okay, let's see stinks. Let's see
I have invented a completely new...
What do you call it? A completely new... System for human-AI collaboration. System. I have... Framework. Platform. Yeah, framework is good. I've invented an entirely new... Put entirely new... Yeah. Oh, wait. I'm putting first what... Or entirely novel. I'm putting first what Ilan said. And now tell me exactly what you're saying. I've invented an entirely new technology. Or I have...
Invent it.
A first ever, first ever is a good term, a first ever way of, and then you add what it does, the first ever way to.
yeah I have I have invented a first ever I like first ever me too because you definitely want to brand it is you are you and first and a really unique idea and unique
Well maybe first ever unique, not quite the same, first ever is the first time, unique is it's... Is there a more concise way of saying it, like at the cutting edge or at the forefront, or... Emerging... Unseen, completely novel, breakthrough technology. Breakthrough is good.
Should you say, I have just invented, or I want to keep it very to the moment. Yeah, exactly. I've just invented a breakthrough, first ever, you can pile it on. I've just invented a breakthrough, first ever means of... But then it sounds like just too much, right? Yeah, you don't want to be over the top. One, one. You kind of do want to be over the top. No, they keep on giving advice of saying, don't be over the top. Just, you know, make whatever you're saying, make it understandable and clear. Okay, well then... Don't add fluff. Well then you can say what I believe is the first attempt, or the first successful... Yeah. About the first successful... Proof and success.
but what? I believe I believe I believe I have devised the first successful means of talking to agents well yeah exactly I think this sentence is the best a new system for human interaction so just add that before thanks dad in the past year I've been applying my foreign optimization of my sentence skills towards developing towards developing towards inventing or creating an entirely new entirely new system for human interaction yeah and then I think so now we want our one really concrete sentence um
something about so we want something about something about sits on platform voice tree one phrase of what VT is and then and then the three main use cases sound good
Yeah, sounds good. Should we ask your friend, the AI, to work on that?
How should I add a jump? Yeah
Maybe what's that? No, I can give you the repose knowledge
yc okay ready you're getting
Which one are you? There's two Elans. Oh.
Hey, but you should also give it the full documents of what voice tree is
Like, um...
Remember I gave you one that has...
Don't, um, Voice 3 Closed Core, I think.
It already has that. How do you know? It has memory? Yeah, of course. Really? Yeah. It already has that. Okay, cool.
You
What's that?
notes I was taking.
Hmm
I like what you did more
Remember, you don't want to read it from a script. You want it to be bullet points. Yeah, bullet points. I think what you have is really good, man. I think what you have is better. Let's ask you for specific things. Maybe Gemini's actually better. Rewrite it with Gemini. It's pretty cool, no? Yeah.
Let's see what John was saying.
But you know, for perplexity, your thing would be really useful because it's now putting this entire huge, I mean, look how long this chat is. There's thousands and thousands of things. It's giving that all to you each time. And it's not fast. No, no, no. Imagine if it was 85% faster. Yeah.
And perplexi is worth a lot of money.
All right, that was better.
Elite accomplishment. Show, don't just tell. This is much better than Grok.
It's pretty cool.
It's pretty cool.
This is actually pretty good.
Dad. Hey, you say it. Hey, YC. I'm Manu. I'm a performance engineer at Atlassian, and my obsession is optimization. Last year, I led products in the Jira system that saved our customers $8 million in AWS costs. Now, I'm applying that same obsession to a much bigger performance bottleneck, the way humans and AI work together. I've built VoiceTree, a platform that converts unstructured text from your thoughts, documents, or meetings into an efficient graph. For AI, this slashes LLM context by 85% and boosts accuracy. For you, it's a visual mind map that externalizes your working memory. It's one system that makes both humans and AI smarter. I've recently gone part-time to focus completely on this, and I'm excited to show you the breakthroughs we're making. Let's build this together. That's very good. I don't like the term obsession.
But he has an obsession for optimization, he does, and that shines through. Let's see, let's think of another word for obsession.
I sent it to you? My... I'm completely... My passion. My passion. Yeah. Let me look it up. Let me do that. Yeah, send me that. Key messages I call them. Obsession always has a slightly negative.
Alrighty, okay, so we are working right now on VoiceTree and what have we spent today doing? Today we spent trying to work on our demo. The morning was very productive, we got some nice things done, some nice fix-ups, we got some intuition about the behavior of VoiceTree.
And then we sort of practiced our demo.
The demo, what do you call it? Like a demo.
demo fuck what's it called demo script we worked on a demo script and we got a fairly good demo script working So that is one option for what we could do now. We could work on our demo script
Um...
And then...
We could actually also record the first demo, the first part of the demo. We could get that over and done with, which could be good. And then we were practicing doing some work using VoiceTree, and it was really promising, actually. So that was really impressive. I loved that.
Um...
Cool, and then we spent a lot of time fucking around with terminal zoom positioning And that is just a complete clusterfuck. We should not spend any more time on that. That was such a mistake Really mad about that
Um...
Okay, um...
So now we have this whole other part of the project, which is proving our benchmark results are correct. I don't know exactly how to prioritize that yet. It would be nice to first of all just get some really good demos done. So the first part of the demo we can do, the demo that's just explaining what VoiceTree is.
We can already get that done now. The second part of the demo, which is actually using VoiceTree to work, I still need to get a really good example for.
Okay, so that's one option, those are our options, okay cool.
I think the really amazing thing right now is that the VoiceTree core algorithm is working well enough to actually use it for software engineering, which is pretty damn impressive, actually.
Okay, one really quick thing I want to do is just go into the UI and change the time out of the breathing of animation on nodes. Should actually take almost no time.
Um.
Nice.
And then we'll just get the new nodes that we haven't seen before.
Okay, so we do, we would like to, one thing we need to do is come up with a really good example for what we're going to use for the second part of our demo where we're explaining what the showing using VoiceTree for engineering use case with the agentic part as well.
Um...
And then the other idea we had for
sort of related to validating benchmark results was if VoiceTree actually does improve the benchmarks Well, what we were thinking is that we also just want a tool called answer question from tree
which Claude can then use to answer a question from the tree.
But it's not really demo-able, so there's no point in doing that yet. It is just cool though. So what is demo-able? We could have a large document.
Okay, and then we do...
Okay, so we need to check what the current state of our benchmark is
Um, and what's the best way of doing that? We can...
Just run Claude, I guess. Claude.
Model Sonnet.
And then we want to run sonnet on.
the benchmark we have GSM infinite main benchmark
I think I have that somewhere.
Oh, that's in a completely different branch.
Mmm.
Okay.
Okay, we might need to switch branches to have a look at what the state of that is.
Um, should we first film the demo?
All right, testing one, two, three, look at me, what's my name?
all right now let's send that over to the buffer and see what they do with it
Hey Siri, where are you?
Mason and I've been busy building soft
a new system for human and AI.
This system is rent surrounded is centered around our core algorithm called voice tree which converts tech streams such as live voice Into a tree representation similar to a mind
It's running live right now.
So what's the benefit of this?
The tree allows for more
increasing cognitive load by providing a memory
relationships between them, rather than getting lost in it.
As we'll see soon, both humans and LLMs can
On top of this VoiceTree platform,
So much is possible.
We have so far focused on two awesome uses.
Hey, Y-Commander. I'm Manu Mason, and I've been busy building software.
new system for human AI club.
Hey Y commenter, I'm Manu Mason and I've been busy building software.
This system is centered around our core algorithm called voice tree
Which converts text streams such as live voice into a tree representation similar to a mind map
I'm Manu Mason, and I've been busy building software that unlocks
for human-AI collaboration.
This system
Hey Y Combinator, I'm Manu Mason and I've been busy building software that unlocks
Hey Y Combinator, I'm Manu Mason and I've been busy building software that unlocks a new system for human and AI collaboration.
This system is centered around our core algorithm called VoiceTree which converts text streams such as live voice into a tree representation similar to a mind map.
It's running right now.
What's the benefit of this? The tree allows for more...
Decreasing cognitive load by providing memory aid for the high-level concept.
and the relationships between them, rather than getting lost.
As we'll soon see, both humans and elephants
Hey Y Combinator, I'm Manu Mason. I've been busy building software that unlocks a new system for human AI cloud
This system is centered around our core algorithm.
Hey Y Commenter, I'm Manu Mason. I've been busy building software that unlocks a new system for human AI collaboration.
This system is centered around our core algorithm called VoiceTree, which converts text into a visual, text streams, such as live voice, into a tree representation, similar to a mind map.
Hey Y Commenter, I'm Manu Mason and I've been busy building software that unlocks a new system for human AI
This system is centered around our core algorithm called VoiceTree, which converts text...
streams such as live voice into a tree representation, similar to a mind map.
Hey Y Combinator, I'm Manu and this last year I've been busy building
Hey Y Combinator, I'm Manu. I've been busy building software that unlocks a new system for human AI
This system is centered around our core algorithm called VoiceTree, which converts text streams, such as live voice, into a tree representation, similar to a mind map. It's running right now live.
What's the benefit of this? The tree allows for a more efficient representation of content, decreasing cognitive load by providing
for the high-level concepts and the relationships between them rather than getting lost in the
As we'll see soon, both humans and LLMs can...
On top of this VoiceTree platform, so much is possible.
We've so far focused on two awesome users.
The first is an interface for software engineers.
The second is improving agents themselves through compressing and better representing
Hey Y Combinator, I'm Manu, I've been busy building software that unlocks a new system for human AI collaboration. This system is centered around our core algorithm called VoiceTree, which converts text streams, such as live voice, into a tree representation, similar to my mind map.
This system is centered on our core algorithm called VoiceTree, which converts text streams, such as live voice, into a tree representation similar to a mind map. It's running right now live.
What's the benefit of this? The tree allows for more efficient representation.
Decreasing cognitive load by providing a memory aid for the high-level concepts and relationships between them, rather than getting lost in the detail. As we'll see soon, both humans and LLMs can benefit from this.
On top of this Voistry platform, so much as possible, we've so far focused on two awesome use cases. The first is an interface for software engineers to manage multiple .
The second is improving agents themselves through compressing and better representing their context with VoiceTree.
